{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22d4283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T03:32:20.285576Z",
     "start_time": "2023-06-05T03:32:18.559542Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wrq/anaconda3/envs/quant/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx,_convert_fx,convert_to_reference_fx\n",
    "from torch.ao.quantization import QConfigMapping\n",
    "import torchvision\n",
    "import timm\n",
    "import pprint\n",
    "import onnx\n",
    "import thop\n",
    "import onnxruntime as rt\n",
    "from scipy import spatial\n",
    "import os,shutil\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6af71df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T03:32:21.179865Z",
     "start_time": "2023-06-05T03:32:21.161054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bat_resnext26ts.ch_in1k',\n",
      " 'beit_base_patch16_224.in22k_ft_in22k',\n",
      " 'beit_base_patch16_224.in22k_ft_in22k_in1k',\n",
      " 'beit_base_patch16_384.in22k_ft_in22k_in1k',\n",
      " 'beit_large_patch16_224.in22k_ft_in22k',\n",
      " 'beit_large_patch16_224.in22k_ft_in22k_in1k',\n",
      " 'beit_large_patch16_384.in22k_ft_in22k_in1k',\n",
      " 'beit_large_patch16_512.in22k_ft_in22k_in1k',\n",
      " 'beitv2_base_patch16_224.in1k_ft_in1k',\n",
      " 'beitv2_base_patch16_224.in1k_ft_in22k',\n",
      " 'beitv2_base_patch16_224.in1k_ft_in22k_in1k',\n",
      " 'beitv2_large_patch16_224.in1k_ft_in1k',\n",
      " 'beitv2_large_patch16_224.in1k_ft_in22k',\n",
      " 'beitv2_large_patch16_224.in1k_ft_in22k_in1k',\n",
      " 'botnet26t_256.c1_in1k',\n",
      " 'caformer_b36.sail_in1k',\n",
      " 'caformer_b36.sail_in1k_384',\n",
      " 'caformer_b36.sail_in22k',\n",
      " 'caformer_b36.sail_in22k_ft_in1k',\n",
      " 'caformer_b36.sail_in22k_ft_in1k_384',\n",
      " 'caformer_m36.sail_in1k',\n",
      " 'caformer_m36.sail_in1k_384',\n",
      " 'caformer_m36.sail_in22k',\n",
      " 'caformer_m36.sail_in22k_ft_in1k',\n",
      " 'caformer_m36.sail_in22k_ft_in1k_384',\n",
      " 'caformer_s18.sail_in1k',\n",
      " 'caformer_s18.sail_in1k_384',\n",
      " 'caformer_s18.sail_in22k',\n",
      " 'caformer_s18.sail_in22k_ft_in1k',\n",
      " 'caformer_s18.sail_in22k_ft_in1k_384',\n",
      " 'caformer_s36.sail_in1k',\n",
      " 'caformer_s36.sail_in1k_384',\n",
      " 'caformer_s36.sail_in22k',\n",
      " 'caformer_s36.sail_in22k_ft_in1k',\n",
      " 'caformer_s36.sail_in22k_ft_in1k_384',\n",
      " 'cait_m36_384.fb_dist_in1k',\n",
      " 'cait_m48_448.fb_dist_in1k',\n",
      " 'cait_s24_224.fb_dist_in1k',\n",
      " 'cait_s24_384.fb_dist_in1k',\n",
      " 'cait_s36_384.fb_dist_in1k',\n",
      " 'cait_xs24_384.fb_dist_in1k',\n",
      " 'cait_xxs24_224.fb_dist_in1k',\n",
      " 'cait_xxs24_384.fb_dist_in1k',\n",
      " 'cait_xxs36_224.fb_dist_in1k',\n",
      " 'cait_xxs36_384.fb_dist_in1k',\n",
      " 'coat_lite_medium.in1k',\n",
      " 'coat_lite_medium_384.in1k',\n",
      " 'coat_lite_mini.in1k',\n",
      " 'coat_lite_small.in1k',\n",
      " 'coat_lite_tiny.in1k',\n",
      " 'coat_mini.in1k',\n",
      " 'coat_small.in1k',\n",
      " 'coat_tiny.in1k',\n",
      " 'coatnet_0_rw_224.sw_in1k',\n",
      " 'coatnet_1_rw_224.sw_in1k',\n",
      " 'coatnet_2_rw_224.sw_in12k',\n",
      " 'coatnet_2_rw_224.sw_in12k_ft_in1k',\n",
      " 'coatnet_3_rw_224.sw_in12k',\n",
      " 'coatnet_bn_0_rw_224.sw_in1k',\n",
      " 'coatnet_nano_rw_224.sw_in1k',\n",
      " 'coatnet_rmlp_1_rw2_224.sw_in12k',\n",
      " 'coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k',\n",
      " 'coatnet_rmlp_1_rw_224.sw_in1k',\n",
      " 'coatnet_rmlp_2_rw_224.sw_in1k',\n",
      " 'coatnet_rmlp_2_rw_224.sw_in12k',\n",
      " 'coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k',\n",
      " 'coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k',\n",
      " 'coatnet_rmlp_nano_rw_224.sw_in1k',\n",
      " 'coatnext_nano_rw_224.sw_in1k',\n",
      " 'convformer_b36.sail_in1k',\n",
      " 'convformer_b36.sail_in1k_384',\n",
      " 'convformer_b36.sail_in22k',\n",
      " 'convformer_b36.sail_in22k_ft_in1k',\n",
      " 'convformer_b36.sail_in22k_ft_in1k_384',\n",
      " 'convformer_m36.sail_in1k',\n",
      " 'convformer_m36.sail_in1k_384',\n",
      " 'convformer_m36.sail_in22k',\n",
      " 'convformer_m36.sail_in22k_ft_in1k',\n",
      " 'convformer_m36.sail_in22k_ft_in1k_384',\n",
      " 'convformer_s18.sail_in1k',\n",
      " 'convformer_s18.sail_in1k_384',\n",
      " 'convformer_s18.sail_in22k',\n",
      " 'convformer_s18.sail_in22k_ft_in1k',\n",
      " 'convformer_s18.sail_in22k_ft_in1k_384',\n",
      " 'convformer_s36.sail_in1k',\n",
      " 'convformer_s36.sail_in1k_384',\n",
      " 'convformer_s36.sail_in22k',\n",
      " 'convformer_s36.sail_in22k_ft_in1k',\n",
      " 'convformer_s36.sail_in22k_ft_in1k_384',\n",
      " 'convit_base.fb_in1k',\n",
      " 'convit_small.fb_in1k',\n",
      " 'convit_tiny.fb_in1k',\n",
      " 'convmixer_768_32.in1k',\n",
      " 'convmixer_1024_20_ks9_p14.in1k',\n",
      " 'convmixer_1536_20.in1k',\n",
      " 'convnext_atto.d2_in1k',\n",
      " 'convnext_atto_ols.a2_in1k',\n",
      " 'convnext_base.clip_laion2b',\n",
      " 'convnext_base.clip_laion2b_augreg',\n",
      " 'convnext_base.clip_laion2b_augreg_ft_in1k',\n",
      " 'convnext_base.clip_laion2b_augreg_ft_in12k',\n",
      " 'convnext_base.clip_laion2b_augreg_ft_in12k_in1k',\n",
      " 'convnext_base.clip_laion2b_augreg_ft_in12k_in1k_384',\n",
      " 'convnext_base.clip_laiona',\n",
      " 'convnext_base.clip_laiona_320',\n",
      " 'convnext_base.clip_laiona_augreg_320',\n",
      " 'convnext_base.clip_laiona_augreg_ft_in1k_384',\n",
      " 'convnext_base.fb_in1k',\n",
      " 'convnext_base.fb_in22k',\n",
      " 'convnext_base.fb_in22k_ft_in1k',\n",
      " 'convnext_base.fb_in22k_ft_in1k_384',\n",
      " 'convnext_femto.d1_in1k',\n",
      " 'convnext_femto_ols.d1_in1k',\n",
      " 'convnext_large.fb_in1k',\n",
      " 'convnext_large.fb_in22k',\n",
      " 'convnext_large.fb_in22k_ft_in1k',\n",
      " 'convnext_large.fb_in22k_ft_in1k_384',\n",
      " 'convnext_large_mlp.clip_laion2b_augreg',\n",
      " 'convnext_large_mlp.clip_laion2b_augreg_ft_in1k',\n",
      " 'convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384',\n",
      " 'convnext_large_mlp.clip_laion2b_augreg_ft_in12k_384',\n",
      " 'convnext_large_mlp.clip_laion2b_ft_320',\n",
      " 'convnext_large_mlp.clip_laion2b_ft_soup_320',\n",
      " 'convnext_large_mlp.clip_laion2b_soup_ft_in12k_320',\n",
      " 'convnext_large_mlp.clip_laion2b_soup_ft_in12k_384',\n",
      " 'convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_320',\n",
      " 'convnext_large_mlp.clip_laion2b_soup_ft_in12k_in1k_384',\n",
      " 'convnext_nano.d1h_in1k',\n",
      " 'convnext_nano.in12k',\n",
      " 'convnext_nano.in12k_ft_in1k',\n",
      " 'convnext_nano_ols.d1h_in1k',\n",
      " 'convnext_pico.d1_in1k',\n",
      " 'convnext_pico_ols.d1_in1k',\n",
      " 'convnext_small.fb_in1k',\n",
      " 'convnext_small.fb_in22k',\n",
      " 'convnext_small.fb_in22k_ft_in1k',\n",
      " 'convnext_small.fb_in22k_ft_in1k_384',\n",
      " 'convnext_small.in12k',\n",
      " 'convnext_small.in12k_ft_in1k',\n",
      " 'convnext_small.in12k_ft_in1k_384',\n",
      " 'convnext_tiny.fb_in1k',\n",
      " 'convnext_tiny.fb_in22k',\n",
      " 'convnext_tiny.fb_in22k_ft_in1k',\n",
      " 'convnext_tiny.fb_in22k_ft_in1k_384',\n",
      " 'convnext_tiny.in12k',\n",
      " 'convnext_tiny.in12k_ft_in1k',\n",
      " 'convnext_tiny.in12k_ft_in1k_384',\n",
      " 'convnext_tiny_hnf.a2h_in1k',\n",
      " 'convnext_xlarge.fb_in22k',\n",
      " 'convnext_xlarge.fb_in22k_ft_in1k',\n",
      " 'convnext_xlarge.fb_in22k_ft_in1k_384',\n",
      " 'convnext_xxlarge.clip_laion2b_rewind',\n",
      " 'convnext_xxlarge.clip_laion2b_soup',\n",
      " 'convnext_xxlarge.clip_laion2b_soup_ft_in1k',\n",
      " 'convnextv2_atto.fcmae',\n",
      " 'convnextv2_atto.fcmae_ft_in1k',\n",
      " 'convnextv2_base.fcmae',\n",
      " 'convnextv2_base.fcmae_ft_in1k',\n",
      " 'convnextv2_base.fcmae_ft_in22k_in1k',\n",
      " 'convnextv2_base.fcmae_ft_in22k_in1k_384',\n",
      " 'convnextv2_femto.fcmae',\n",
      " 'convnextv2_femto.fcmae_ft_in1k',\n",
      " 'convnextv2_huge.fcmae',\n",
      " 'convnextv2_huge.fcmae_ft_in1k',\n",
      " 'convnextv2_huge.fcmae_ft_in22k_in1k_384',\n",
      " 'convnextv2_huge.fcmae_ft_in22k_in1k_512',\n",
      " 'convnextv2_large.fcmae',\n",
      " 'convnextv2_large.fcmae_ft_in1k',\n",
      " 'convnextv2_large.fcmae_ft_in22k_in1k',\n",
      " 'convnextv2_large.fcmae_ft_in22k_in1k_384',\n",
      " 'convnextv2_nano.fcmae',\n",
      " 'convnextv2_nano.fcmae_ft_in1k',\n",
      " 'convnextv2_nano.fcmae_ft_in22k_in1k',\n",
      " 'convnextv2_nano.fcmae_ft_in22k_in1k_384',\n",
      " 'convnextv2_pico.fcmae',\n",
      " 'convnextv2_pico.fcmae_ft_in1k',\n",
      " 'convnextv2_tiny.fcmae',\n",
      " 'convnextv2_tiny.fcmae_ft_in1k',\n",
      " 'convnextv2_tiny.fcmae_ft_in22k_in1k',\n",
      " 'convnextv2_tiny.fcmae_ft_in22k_in1k_384',\n",
      " 'crossvit_9_240.in1k',\n",
      " 'crossvit_9_dagger_240.in1k',\n",
      " 'crossvit_15_240.in1k',\n",
      " 'crossvit_15_dagger_240.in1k',\n",
      " 'crossvit_15_dagger_408.in1k',\n",
      " 'crossvit_18_240.in1k',\n",
      " 'crossvit_18_dagger_240.in1k',\n",
      " 'crossvit_18_dagger_408.in1k',\n",
      " 'crossvit_base_240.in1k',\n",
      " 'crossvit_small_240.in1k',\n",
      " 'crossvit_tiny_240.in1k',\n",
      " 'cs3darknet_focus_l.c2ns_in1k',\n",
      " 'cs3darknet_focus_m.c2ns_in1k',\n",
      " 'cs3darknet_l.c2ns_in1k',\n",
      " 'cs3darknet_m.c2ns_in1k',\n",
      " 'cs3darknet_x.c2ns_in1k',\n",
      " 'cs3edgenet_x.c2_in1k',\n",
      " 'cs3se_edgenet_x.c2ns_in1k',\n",
      " 'cs3sedarknet_l.c2ns_in1k',\n",
      " 'cs3sedarknet_x.c2ns_in1k',\n",
      " 'cspdarknet53.ra_in1k',\n",
      " 'cspresnet50.ra_in1k',\n",
      " 'cspresnext50.ra_in1k',\n",
      " 'darknet53.c2ns_in1k',\n",
      " 'darknetaa53.c2ns_in1k',\n",
      " 'davit_base.msft_in1k',\n",
      " 'davit_small.msft_in1k',\n",
      " 'davit_tiny.msft_in1k',\n",
      " 'deit3_base_patch16_224.fb_in1k',\n",
      " 'deit3_base_patch16_224.fb_in22k_ft_in1k',\n",
      " 'deit3_base_patch16_384.fb_in1k',\n",
      " 'deit3_base_patch16_384.fb_in22k_ft_in1k',\n",
      " 'deit3_huge_patch14_224.fb_in1k',\n",
      " 'deit3_huge_patch14_224.fb_in22k_ft_in1k',\n",
      " 'deit3_large_patch16_224.fb_in1k',\n",
      " 'deit3_large_patch16_224.fb_in22k_ft_in1k',\n",
      " 'deit3_large_patch16_384.fb_in1k',\n",
      " 'deit3_large_patch16_384.fb_in22k_ft_in1k',\n",
      " 'deit3_medium_patch16_224.fb_in1k',\n",
      " 'deit3_medium_patch16_224.fb_in22k_ft_in1k',\n",
      " 'deit3_small_patch16_224.fb_in1k',\n",
      " 'deit3_small_patch16_224.fb_in22k_ft_in1k',\n",
      " 'deit3_small_patch16_384.fb_in1k',\n",
      " 'deit3_small_patch16_384.fb_in22k_ft_in1k',\n",
      " 'deit_base_distilled_patch16_224.fb_in1k',\n",
      " 'deit_base_distilled_patch16_384.fb_in1k',\n",
      " 'deit_base_patch16_224.fb_in1k',\n",
      " 'deit_base_patch16_384.fb_in1k',\n",
      " 'deit_small_distilled_patch16_224.fb_in1k',\n",
      " 'deit_small_patch16_224.fb_in1k',\n",
      " 'deit_tiny_distilled_patch16_224.fb_in1k',\n",
      " 'deit_tiny_patch16_224.fb_in1k',\n",
      " 'densenet121.ra_in1k',\n",
      " 'densenet121.tv_in1k',\n",
      " 'densenet161.tv_in1k',\n",
      " 'densenet169.tv_in1k',\n",
      " 'densenet201.tv_in1k',\n",
      " 'densenetblur121d.ra_in1k',\n",
      " 'dla34.in1k',\n",
      " 'dla46_c.in1k',\n",
      " 'dla46x_c.in1k',\n",
      " 'dla60.in1k',\n",
      " 'dla60_res2net.in1k',\n",
      " 'dla60_res2next.in1k',\n",
      " 'dla60x.in1k',\n",
      " 'dla60x_c.in1k',\n",
      " 'dla102.in1k',\n",
      " 'dla102x2.in1k',\n",
      " 'dla102x.in1k',\n",
      " 'dla169.in1k',\n",
      " 'dm_nfnet_f0.dm_in1k',\n",
      " 'dm_nfnet_f1.dm_in1k',\n",
      " 'dm_nfnet_f2.dm_in1k',\n",
      " 'dm_nfnet_f3.dm_in1k',\n",
      " 'dm_nfnet_f4.dm_in1k',\n",
      " 'dm_nfnet_f5.dm_in1k',\n",
      " 'dm_nfnet_f6.dm_in1k',\n",
      " 'dpn68.mx_in1k',\n",
      " 'dpn68b.mx_in1k',\n",
      " 'dpn68b.ra_in1k',\n",
      " 'dpn92.mx_in1k',\n",
      " 'dpn98.mx_in1k',\n",
      " 'dpn107.mx_in1k',\n",
      " 'dpn131.mx_in1k',\n",
      " 'eca_botnext26ts_256.c1_in1k',\n",
      " 'eca_halonext26ts.c1_in1k',\n",
      " 'eca_nfnet_l0.ra2_in1k',\n",
      " 'eca_nfnet_l1.ra2_in1k',\n",
      " 'eca_nfnet_l2.ra3_in1k',\n",
      " 'eca_resnet33ts.ra2_in1k',\n",
      " 'eca_resnext26ts.ch_in1k',\n",
      " 'ecaresnet26t.ra2_in1k',\n",
      " 'ecaresnet50d.miil_in1k',\n",
      " 'ecaresnet50d_pruned.miil_in1k',\n",
      " 'ecaresnet50t.a1_in1k',\n",
      " 'ecaresnet50t.a2_in1k',\n",
      " 'ecaresnet50t.a3_in1k',\n",
      " 'ecaresnet50t.ra2_in1k',\n",
      " 'ecaresnet101d.miil_in1k',\n",
      " 'ecaresnet101d_pruned.miil_in1k',\n",
      " 'ecaresnet269d.ra2_in1k',\n",
      " 'ecaresnetlight.miil_in1k',\n",
      " 'edgenext_base.in21k_ft_in1k',\n",
      " 'edgenext_base.usi_in1k',\n",
      " 'edgenext_small.usi_in1k',\n",
      " 'edgenext_small_rw.sw_in1k',\n",
      " 'edgenext_x_small.in1k',\n",
      " 'edgenext_xx_small.in1k',\n",
      " 'efficientformer_l1.snap_dist_in1k',\n",
      " 'efficientformer_l3.snap_dist_in1k',\n",
      " 'efficientformer_l7.snap_dist_in1k',\n",
      " 'efficientformerv2_l.snap_dist_in1k',\n",
      " 'efficientformerv2_s0.snap_dist_in1k',\n",
      " 'efficientformerv2_s1.snap_dist_in1k',\n",
      " 'efficientformerv2_s2.snap_dist_in1k',\n",
      " 'efficientnet_b0.ra_in1k',\n",
      " 'efficientnet_b1.ft_in1k',\n",
      " 'efficientnet_b1_pruned.in1k',\n",
      " 'efficientnet_b2.ra_in1k',\n",
      " 'efficientnet_b2_pruned.in1k',\n",
      " 'efficientnet_b3.ra2_in1k',\n",
      " 'efficientnet_b3_pruned.in1k',\n",
      " 'efficientnet_b4.ra2_in1k',\n",
      " 'efficientnet_b5.sw_in12k',\n",
      " 'efficientnet_b5.sw_in12k_ft_in1k',\n",
      " 'efficientnet_el.ra_in1k',\n",
      " 'efficientnet_el_pruned.in1k',\n",
      " 'efficientnet_em.ra2_in1k',\n",
      " 'efficientnet_es.ra_in1k',\n",
      " 'efficientnet_es_pruned.in1k',\n",
      " 'efficientnet_lite0.ra_in1k',\n",
      " 'efficientnetv2_rw_m.agc_in1k',\n",
      " 'efficientnetv2_rw_s.ra2_in1k',\n",
      " 'efficientnetv2_rw_t.ra2_in1k',\n",
      " 'ese_vovnet19b_dw.ra_in1k',\n",
      " 'ese_vovnet39b.ra_in1k',\n",
      " 'eva02_base_patch14_224.mim_in22k',\n",
      " 'eva02_base_patch14_448.mim_in22k_ft_in1k',\n",
      " 'eva02_base_patch14_448.mim_in22k_ft_in22k',\n",
      " 'eva02_base_patch14_448.mim_in22k_ft_in22k_in1k',\n",
      " 'eva02_base_patch16_clip_224.merged2b',\n",
      " 'eva02_enormous_patch14_clip_224.laion2b',\n",
      " 'eva02_enormous_patch14_clip_224.laion2b_plus',\n",
      " 'eva02_large_patch14_224.mim_in22k',\n",
      " 'eva02_large_patch14_224.mim_m38m',\n",
      " 'eva02_large_patch14_448.mim_in22k_ft_in1k',\n",
      " 'eva02_large_patch14_448.mim_in22k_ft_in22k',\n",
      " 'eva02_large_patch14_448.mim_in22k_ft_in22k_in1k',\n",
      " 'eva02_large_patch14_448.mim_m38m_ft_in1k',\n",
      " 'eva02_large_patch14_448.mim_m38m_ft_in22k',\n",
      " 'eva02_large_patch14_448.mim_m38m_ft_in22k_in1k',\n",
      " 'eva02_large_patch14_clip_224.merged2b',\n",
      " 'eva02_large_patch14_clip_336.merged2b',\n",
      " 'eva02_small_patch14_224.mim_in22k',\n",
      " 'eva02_small_patch14_336.mim_in22k_ft_in1k',\n",
      " 'eva02_tiny_patch14_224.mim_in22k',\n",
      " 'eva02_tiny_patch14_336.mim_in22k_ft_in1k',\n",
      " 'eva_giant_patch14_224.clip_ft_in1k',\n",
      " 'eva_giant_patch14_336.clip_ft_in1k',\n",
      " 'eva_giant_patch14_336.m30m_ft_in22k_in1k',\n",
      " 'eva_giant_patch14_560.m30m_ft_in22k_in1k',\n",
      " 'eva_giant_patch14_clip_224.laion400m',\n",
      " 'eva_giant_patch14_clip_224.merged2b',\n",
      " 'eva_large_patch14_196.in22k_ft_in1k',\n",
      " 'eva_large_patch14_196.in22k_ft_in22k_in1k',\n",
      " 'eva_large_patch14_336.in22k_ft_in1k',\n",
      " 'eva_large_patch14_336.in22k_ft_in22k_in1k',\n",
      " 'fbnetc_100.rmsp_in1k',\n",
      " 'fbnetv3_b.ra2_in1k',\n",
      " 'fbnetv3_d.ra2_in1k',\n",
      " 'fbnetv3_g.ra2_in1k',\n",
      " 'flexivit_base.300ep_in1k',\n",
      " 'flexivit_base.300ep_in21k',\n",
      " 'flexivit_base.600ep_in1k',\n",
      " 'flexivit_base.1000ep_in21k',\n",
      " 'flexivit_base.1200ep_in1k',\n",
      " 'flexivit_base.patch16_in21k',\n",
      " 'flexivit_base.patch30_in21k',\n",
      " 'flexivit_large.300ep_in1k',\n",
      " 'flexivit_large.600ep_in1k',\n",
      " 'flexivit_large.1200ep_in1k',\n",
      " 'flexivit_small.300ep_in1k',\n",
      " 'flexivit_small.600ep_in1k',\n",
      " 'flexivit_small.1200ep_in1k',\n",
      " 'focalnet_base_lrf.ms_in1k',\n",
      " 'focalnet_base_srf.ms_in1k',\n",
      " 'focalnet_huge_fl3.ms_in22k',\n",
      " 'focalnet_huge_fl4.ms_in22k',\n",
      " 'focalnet_large_fl3.ms_in22k',\n",
      " 'focalnet_large_fl4.ms_in22k',\n",
      " 'focalnet_small_lrf.ms_in1k',\n",
      " 'focalnet_small_srf.ms_in1k',\n",
      " 'focalnet_tiny_lrf.ms_in1k',\n",
      " 'focalnet_tiny_srf.ms_in1k',\n",
      " 'focalnet_xlarge_fl3.ms_in22k',\n",
      " 'focalnet_xlarge_fl4.ms_in22k',\n",
      " 'gc_efficientnetv2_rw_t.agc_in1k',\n",
      " 'gcresnet33ts.ra2_in1k',\n",
      " 'gcresnet50t.ra2_in1k',\n",
      " 'gcresnext26ts.ch_in1k',\n",
      " 'gcresnext50ts.ch_in1k',\n",
      " 'gcvit_base.in1k',\n",
      " 'gcvit_small.in1k',\n",
      " 'gcvit_tiny.in1k',\n",
      " 'gcvit_xtiny.in1k',\n",
      " 'gcvit_xxtiny.in1k',\n",
      " 'gernet_l.idstcv_in1k',\n",
      " 'gernet_m.idstcv_in1k',\n",
      " 'gernet_s.idstcv_in1k',\n",
      " 'ghostnet_100.in1k',\n",
      " 'gmixer_24_224.ra3_in1k',\n",
      " 'gmlp_s16_224.ra3_in1k',\n",
      " 'halo2botnet50ts_256.a1h_in1k',\n",
      " 'halonet26t.a1h_in1k',\n",
      " 'halonet50ts.a1h_in1k',\n",
      " 'haloregnetz_b.ra3_in1k',\n",
      " 'hardcorenas_a.miil_green_in1k',\n",
      " 'hardcorenas_b.miil_green_in1k',\n",
      " 'hardcorenas_c.miil_green_in1k',\n",
      " 'hardcorenas_d.miil_green_in1k',\n",
      " 'hardcorenas_e.miil_green_in1k',\n",
      " 'hardcorenas_f.miil_green_in1k',\n",
      " 'hrnet_w18.ms_aug_in1k',\n",
      " 'hrnet_w18.ms_in1k',\n",
      " 'hrnet_w18_small.ms_in1k',\n",
      " 'hrnet_w18_small_v2.ms_in1k',\n",
      " 'hrnet_w18_ssld.paddle_in1k',\n",
      " 'hrnet_w30.ms_in1k',\n",
      " 'hrnet_w32.ms_in1k',\n",
      " 'hrnet_w40.ms_in1k',\n",
      " 'hrnet_w44.ms_in1k',\n",
      " 'hrnet_w48.ms_in1k',\n",
      " 'hrnet_w48_ssld.paddle_in1k',\n",
      " 'hrnet_w64.ms_in1k',\n",
      " 'inception_resnet_v2.tf_ens_adv_in1k',\n",
      " 'inception_resnet_v2.tf_in1k',\n",
      " 'inception_v3.gluon_in1k',\n",
      " 'inception_v3.tf_adv_in1k',\n",
      " 'inception_v3.tf_in1k',\n",
      " 'inception_v3.tv_in1k',\n",
      " 'inception_v4.tf_in1k',\n",
      " 'lambda_resnet26rpt_256.c1_in1k',\n",
      " 'lambda_resnet26t.c1_in1k',\n",
      " 'lambda_resnet50ts.a1h_in1k',\n",
      " 'lamhalobotnet50ts_256.a1h_in1k',\n",
      " 'lcnet_050.ra2_in1k',\n",
      " 'lcnet_075.ra2_in1k',\n",
      " 'lcnet_100.ra2_in1k',\n",
      " 'legacy_senet154.in1k',\n",
      " 'legacy_seresnet18.in1k',\n",
      " 'legacy_seresnet34.in1k',\n",
      " 'legacy_seresnet50.in1k',\n",
      " 'legacy_seresnet101.in1k',\n",
      " 'legacy_seresnet152.in1k',\n",
      " 'legacy_seresnext26_32x4d.in1k',\n",
      " 'legacy_seresnext50_32x4d.in1k',\n",
      " 'legacy_seresnext101_32x4d.in1k',\n",
      " 'legacy_xception.tf_in1k',\n",
      " 'levit_128.fb_dist_in1k',\n",
      " 'levit_128s.fb_dist_in1k',\n",
      " 'levit_192.fb_dist_in1k',\n",
      " 'levit_256.fb_dist_in1k',\n",
      " 'levit_384.fb_dist_in1k',\n",
      " 'levit_conv_128.fb_dist_in1k',\n",
      " 'levit_conv_128s.fb_dist_in1k',\n",
      " 'levit_conv_192.fb_dist_in1k',\n",
      " 'levit_conv_256.fb_dist_in1k',\n",
      " 'levit_conv_384.fb_dist_in1k',\n",
      " 'maxvit_base_tf_224.in1k',\n",
      " 'maxvit_base_tf_224.in21k',\n",
      " 'maxvit_base_tf_384.in1k',\n",
      " 'maxvit_base_tf_384.in21k_ft_in1k',\n",
      " 'maxvit_base_tf_512.in1k',\n",
      " 'maxvit_base_tf_512.in21k_ft_in1k',\n",
      " 'maxvit_large_tf_224.in1k',\n",
      " 'maxvit_large_tf_224.in21k',\n",
      " 'maxvit_large_tf_384.in1k',\n",
      " 'maxvit_large_tf_384.in21k_ft_in1k',\n",
      " 'maxvit_large_tf_512.in1k',\n",
      " 'maxvit_large_tf_512.in21k_ft_in1k',\n",
      " 'maxvit_nano_rw_256.sw_in1k',\n",
      " 'maxvit_rmlp_base_rw_224.sw_in12k',\n",
      " 'maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
      " 'maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k',\n",
      " 'maxvit_rmlp_nano_rw_256.sw_in1k',\n",
      " 'maxvit_rmlp_pico_rw_256.sw_in1k',\n",
      " 'maxvit_rmlp_small_rw_224.sw_in1k',\n",
      " 'maxvit_rmlp_tiny_rw_256.sw_in1k',\n",
      " 'maxvit_small_tf_224.in1k',\n",
      " 'maxvit_small_tf_384.in1k',\n",
      " 'maxvit_small_tf_512.in1k',\n",
      " 'maxvit_tiny_rw_224.sw_in1k',\n",
      " 'maxvit_tiny_tf_224.in1k',\n",
      " 'maxvit_tiny_tf_384.in1k',\n",
      " 'maxvit_tiny_tf_512.in1k',\n",
      " 'maxvit_xlarge_tf_224.in21k',\n",
      " 'maxvit_xlarge_tf_384.in21k_ft_in1k',\n",
      " 'maxvit_xlarge_tf_512.in21k_ft_in1k',\n",
      " 'maxxvit_rmlp_nano_rw_256.sw_in1k',\n",
      " 'maxxvit_rmlp_small_rw_256.sw_in1k',\n",
      " 'maxxvitv2_nano_rw_256.sw_in1k',\n",
      " 'maxxvitv2_rmlp_base_rw_224.sw_in12k',\n",
      " 'maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
      " 'maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k',\n",
      " 'mixer_b16_224.goog_in21k',\n",
      " 'mixer_b16_224.goog_in21k_ft_in1k',\n",
      " 'mixer_b16_224.miil_in21k',\n",
      " 'mixer_b16_224.miil_in21k_ft_in1k',\n",
      " 'mixer_l16_224.goog_in21k',\n",
      " 'mixer_l16_224.goog_in21k_ft_in1k',\n",
      " 'mixnet_l.ft_in1k',\n",
      " 'mixnet_m.ft_in1k',\n",
      " 'mixnet_s.ft_in1k',\n",
      " 'mixnet_xl.ra_in1k',\n",
      " 'mnasnet_100.rmsp_in1k',\n",
      " 'mnasnet_small.lamb_in1k',\n",
      " 'mobilenetv2_050.lamb_in1k',\n",
      " 'mobilenetv2_100.ra_in1k',\n",
      " 'mobilenetv2_110d.ra_in1k',\n",
      " 'mobilenetv2_120d.ra_in1k',\n",
      " 'mobilenetv2_140.ra_in1k',\n",
      " 'mobilenetv3_large_100.miil_in21k',\n",
      " 'mobilenetv3_large_100.miil_in21k_ft_in1k',\n",
      " 'mobilenetv3_large_100.ra_in1k',\n",
      " 'mobilenetv3_rw.rmsp_in1k',\n",
      " 'mobilenetv3_small_050.lamb_in1k',\n",
      " 'mobilenetv3_small_075.lamb_in1k',\n",
      " 'mobilenetv3_small_100.lamb_in1k',\n",
      " 'mobilevit_s.cvnets_in1k',\n",
      " 'mobilevit_xs.cvnets_in1k',\n",
      " 'mobilevit_xxs.cvnets_in1k',\n",
      " 'mobilevitv2_050.cvnets_in1k',\n",
      " 'mobilevitv2_075.cvnets_in1k',\n",
      " 'mobilevitv2_100.cvnets_in1k',\n",
      " 'mobilevitv2_125.cvnets_in1k',\n",
      " 'mobilevitv2_150.cvnets_in1k',\n",
      " 'mobilevitv2_150.cvnets_in22k_ft_in1k',\n",
      " 'mobilevitv2_150.cvnets_in22k_ft_in1k_384',\n",
      " 'mobilevitv2_175.cvnets_in1k',\n",
      " 'mobilevitv2_175.cvnets_in22k_ft_in1k',\n",
      " 'mobilevitv2_175.cvnets_in22k_ft_in1k_384',\n",
      " 'mobilevitv2_200.cvnets_in1k',\n",
      " 'mobilevitv2_200.cvnets_in22k_ft_in1k',\n",
      " 'mobilevitv2_200.cvnets_in22k_ft_in1k_384',\n",
      " 'mvitv2_base.fb_in1k',\n",
      " 'mvitv2_base_cls.fb_inw21k',\n",
      " 'mvitv2_huge_cls.fb_inw21k',\n",
      " 'mvitv2_large.fb_in1k',\n",
      " 'mvitv2_large_cls.fb_inw21k',\n",
      " 'mvitv2_small.fb_in1k',\n",
      " 'mvitv2_tiny.fb_in1k',\n",
      " 'nasnetalarge.tf_in1k',\n",
      " 'nest_base_jx.goog_in1k',\n",
      " 'nest_small_jx.goog_in1k',\n",
      " 'nest_tiny_jx.goog_in1k',\n",
      " 'nf_regnet_b1.ra2_in1k',\n",
      " 'nf_resnet50.ra2_in1k',\n",
      " 'nfnet_l0.ra2_in1k',\n",
      " 'pit_b_224.in1k',\n",
      " 'pit_b_distilled_224.in1k',\n",
      " 'pit_s_224.in1k',\n",
      " 'pit_s_distilled_224.in1k',\n",
      " 'pit_ti_224.in1k',\n",
      " 'pit_ti_distilled_224.in1k',\n",
      " 'pit_xs_224.in1k',\n",
      " 'pit_xs_distilled_224.in1k',\n",
      " 'pnasnet5large.tf_in1k',\n",
      " 'poolformer_m36.sail_in1k',\n",
      " 'poolformer_m48.sail_in1k',\n",
      " 'poolformer_s12.sail_in1k',\n",
      " 'poolformer_s24.sail_in1k',\n",
      " 'poolformer_s36.sail_in1k',\n",
      " 'poolformerv2_m36.sail_in1k',\n",
      " 'poolformerv2_m48.sail_in1k',\n",
      " 'poolformerv2_s12.sail_in1k',\n",
      " 'poolformerv2_s24.sail_in1k',\n",
      " 'poolformerv2_s36.sail_in1k',\n",
      " 'pvt_v2_b0.in1k',\n",
      " 'pvt_v2_b1.in1k',\n",
      " 'pvt_v2_b2.in1k',\n",
      " 'pvt_v2_b2_li.in1k',\n",
      " 'pvt_v2_b3.in1k',\n",
      " 'pvt_v2_b4.in1k',\n",
      " 'pvt_v2_b5.in1k',\n",
      " 'regnetv_040.ra3_in1k',\n",
      " 'regnetv_064.ra3_in1k',\n",
      " 'regnetx_002.pycls_in1k',\n",
      " 'regnetx_004.pycls_in1k',\n",
      " 'regnetx_004_tv.tv2_in1k',\n",
      " 'regnetx_006.pycls_in1k',\n",
      " 'regnetx_008.pycls_in1k',\n",
      " 'regnetx_008.tv2_in1k',\n",
      " 'regnetx_016.pycls_in1k',\n",
      " 'regnetx_016.tv2_in1k',\n",
      " 'regnetx_032.pycls_in1k',\n",
      " 'regnetx_032.tv2_in1k',\n",
      " 'regnetx_040.pycls_in1k',\n",
      " 'regnetx_064.pycls_in1k',\n",
      " 'regnetx_080.pycls_in1k',\n",
      " 'regnetx_080.tv2_in1k',\n",
      " 'regnetx_120.pycls_in1k',\n",
      " 'regnetx_160.pycls_in1k',\n",
      " 'regnetx_160.tv2_in1k',\n",
      " 'regnetx_320.pycls_in1k',\n",
      " 'regnetx_320.tv2_in1k',\n",
      " 'regnety_002.pycls_in1k',\n",
      " 'regnety_004.pycls_in1k',\n",
      " 'regnety_004.tv2_in1k',\n",
      " 'regnety_006.pycls_in1k',\n",
      " 'regnety_008.pycls_in1k',\n",
      " 'regnety_008_tv.tv2_in1k',\n",
      " 'regnety_016.pycls_in1k',\n",
      " 'regnety_016.tv2_in1k',\n",
      " 'regnety_032.pycls_in1k',\n",
      " 'regnety_032.ra_in1k',\n",
      " 'regnety_032.tv2_in1k',\n",
      " 'regnety_040.pycls_in1k',\n",
      " 'regnety_040.ra3_in1k',\n",
      " 'regnety_064.pycls_in1k',\n",
      " 'regnety_064.ra3_in1k',\n",
      " 'regnety_080.pycls_in1k',\n",
      " 'regnety_080.ra3_in1k',\n",
      " 'regnety_080_tv.tv2_in1k',\n",
      " 'regnety_120.pycls_in1k',\n",
      " 'regnety_120.sw_in12k',\n",
      " 'regnety_120.sw_in12k_ft_in1k',\n",
      " 'regnety_160.deit_in1k',\n",
      " 'regnety_160.lion_in12k_ft_in1k',\n",
      " 'regnety_160.pycls_in1k',\n",
      " 'regnety_160.sw_in12k',\n",
      " 'regnety_160.sw_in12k_ft_in1k',\n",
      " 'regnety_160.swag_ft_in1k',\n",
      " 'regnety_160.swag_lc_in1k',\n",
      " 'regnety_160.tv2_in1k',\n",
      " 'regnety_320.pycls_in1k',\n",
      " 'regnety_320.seer',\n",
      " 'regnety_320.seer_ft_in1k',\n",
      " 'regnety_320.swag_ft_in1k',\n",
      " 'regnety_320.swag_lc_in1k',\n",
      " 'regnety_320.tv2_in1k',\n",
      " 'regnety_640.seer',\n",
      " 'regnety_640.seer_ft_in1k',\n",
      " 'regnety_1280.seer',\n",
      " 'regnety_1280.seer_ft_in1k',\n",
      " 'regnety_1280.swag_ft_in1k',\n",
      " 'regnety_1280.swag_lc_in1k',\n",
      " 'regnety_2560.seer_ft_in1k',\n",
      " 'regnetz_040.ra3_in1k',\n",
      " 'regnetz_040_h.ra3_in1k',\n",
      " 'regnetz_b16.ra3_in1k',\n",
      " 'regnetz_c16.ra3_in1k',\n",
      " 'regnetz_c16_evos.ch_in1k',\n",
      " 'regnetz_d8.ra3_in1k',\n",
      " 'regnetz_d8_evos.ch_in1k',\n",
      " 'regnetz_d32.ra3_in1k',\n",
      " 'regnetz_e8.ra3_in1k',\n",
      " 'repvgg_a2.rvgg_in1k',\n",
      " 'repvgg_b0.rvgg_in1k',\n",
      " 'repvgg_b1.rvgg_in1k',\n",
      " 'repvgg_b1g4.rvgg_in1k',\n",
      " 'repvgg_b2.rvgg_in1k',\n",
      " 'repvgg_b2g4.rvgg_in1k',\n",
      " 'repvgg_b3.rvgg_in1k',\n",
      " 'repvgg_b3g4.rvgg_in1k',\n",
      " 'res2net50_14w_8s.in1k',\n",
      " 'res2net50_26w_4s.in1k',\n",
      " 'res2net50_26w_6s.in1k',\n",
      " 'res2net50_26w_8s.in1k',\n",
      " 'res2net50_48w_2s.in1k',\n",
      " 'res2net50d.in1k',\n",
      " 'res2net101_26w_4s.in1k',\n",
      " 'res2net101d.in1k',\n",
      " 'res2next50.in1k',\n",
      " 'resmlp_12_224.fb_dino',\n",
      " 'resmlp_12_224.fb_distilled_in1k',\n",
      " 'resmlp_12_224.fb_in1k',\n",
      " 'resmlp_24_224.fb_dino',\n",
      " 'resmlp_24_224.fb_distilled_in1k',\n",
      " 'resmlp_24_224.fb_in1k',\n",
      " 'resmlp_36_224.fb_distilled_in1k',\n",
      " 'resmlp_36_224.fb_in1k',\n",
      " 'resmlp_big_24_224.fb_distilled_in1k',\n",
      " 'resmlp_big_24_224.fb_in1k',\n",
      " 'resmlp_big_24_224.fb_in22k_ft_in1k',\n",
      " 'resnest14d.gluon_in1k',\n",
      " 'resnest26d.gluon_in1k',\n",
      " 'resnest50d.in1k',\n",
      " 'resnest50d_1s4x24d.in1k',\n",
      " 'resnest50d_4s2x40d.in1k',\n",
      " 'resnest101e.in1k',\n",
      " 'resnest200e.in1k',\n",
      " 'resnest269e.in1k',\n",
      " 'resnet10t.c3_in1k',\n",
      " 'resnet14t.c3_in1k',\n",
      " 'resnet18.a1_in1k',\n",
      " 'resnet18.a2_in1k',\n",
      " 'resnet18.a3_in1k',\n",
      " 'resnet18.fb_ssl_yfcc100m_ft_in1k',\n",
      " 'resnet18.fb_swsl_ig1b_ft_in1k',\n",
      " 'resnet18.gluon_in1k',\n",
      " 'resnet18.tv_in1k',\n",
      " 'resnet18d.ra2_in1k',\n",
      " 'resnet26.bt_in1k',\n",
      " 'resnet26d.bt_in1k',\n",
      " 'resnet26t.ra2_in1k',\n",
      " 'resnet32ts.ra2_in1k',\n",
      " 'resnet33ts.ra2_in1k',\n",
      " 'resnet34.a1_in1k',\n",
      " 'resnet34.a2_in1k',\n",
      " 'resnet34.a3_in1k',\n",
      " 'resnet34.bt_in1k',\n",
      " 'resnet34.gluon_in1k',\n",
      " 'resnet34.tv_in1k',\n",
      " 'resnet34d.ra2_in1k',\n",
      " 'resnet50.a1_in1k',\n",
      " 'resnet50.a1h_in1k',\n",
      " 'resnet50.a2_in1k',\n",
      " 'resnet50.a3_in1k',\n",
      " 'resnet50.am_in1k',\n",
      " 'resnet50.b1k_in1k',\n",
      " 'resnet50.b2k_in1k',\n",
      " 'resnet50.bt_in1k',\n",
      " 'resnet50.c1_in1k',\n",
      " 'resnet50.c2_in1k',\n",
      " 'resnet50.d_in1k',\n",
      " 'resnet50.fb_ssl_yfcc100m_ft_in1k',\n",
      " 'resnet50.fb_swsl_ig1b_ft_in1k',\n",
      " 'resnet50.gluon_in1k',\n",
      " 'resnet50.ra_in1k',\n",
      " 'resnet50.ram_in1k',\n",
      " 'resnet50.tv2_in1k',\n",
      " 'resnet50.tv_in1k',\n",
      " 'resnet50_gn.a1h_in1k',\n",
      " 'resnet50c.gluon_in1k',\n",
      " 'resnet50d.a1_in1k',\n",
      " 'resnet50d.a2_in1k',\n",
      " 'resnet50d.a3_in1k',\n",
      " 'resnet50d.gluon_in1k',\n",
      " 'resnet50d.ra2_in1k',\n",
      " 'resnet50s.gluon_in1k',\n",
      " 'resnet51q.ra2_in1k',\n",
      " 'resnet61q.ra2_in1k',\n",
      " 'resnet101.a1_in1k',\n",
      " 'resnet101.a1h_in1k',\n",
      " 'resnet101.a2_in1k',\n",
      " 'resnet101.a3_in1k',\n",
      " 'resnet101.gluon_in1k',\n",
      " 'resnet101.tv2_in1k',\n",
      " 'resnet101.tv_in1k',\n",
      " 'resnet101c.gluon_in1k',\n",
      " 'resnet101d.gluon_in1k',\n",
      " 'resnet101d.ra2_in1k',\n",
      " 'resnet101s.gluon_in1k',\n",
      " 'resnet152.a1_in1k',\n",
      " 'resnet152.a1h_in1k',\n",
      " 'resnet152.a2_in1k',\n",
      " 'resnet152.a3_in1k',\n",
      " 'resnet152.gluon_in1k',\n",
      " 'resnet152.tv2_in1k',\n",
      " 'resnet152.tv_in1k',\n",
      " 'resnet152c.gluon_in1k',\n",
      " 'resnet152d.gluon_in1k',\n",
      " 'resnet152d.ra2_in1k',\n",
      " 'resnet152s.gluon_in1k',\n",
      " 'resnet200d.ra2_in1k',\n",
      " 'resnetaa50.a1h_in1k',\n",
      " 'resnetaa50d.d_in12k',\n",
      " 'resnetaa50d.sw_in12k',\n",
      " 'resnetaa50d.sw_in12k_ft_in1k',\n",
      " 'resnetaa101d.sw_in12k',\n",
      " 'resnetaa101d.sw_in12k_ft_in1k',\n",
      " 'resnetblur50.bt_in1k',\n",
      " 'resnetrs50.tf_in1k',\n",
      " 'resnetrs101.tf_in1k',\n",
      " 'resnetrs152.tf_in1k',\n",
      " 'resnetrs200.tf_in1k',\n",
      " 'resnetrs270.tf_in1k',\n",
      " 'resnetrs350.tf_in1k',\n",
      " 'resnetrs420.tf_in1k',\n",
      " 'resnetv2_50.a1h_in1k',\n",
      " 'resnetv2_50d_evos.ah_in1k',\n",
      " 'resnetv2_50d_gn.ah_in1k',\n",
      " 'resnetv2_50x1_bit.goog_distilled_in1k',\n",
      " 'resnetv2_50x1_bit.goog_in21k',\n",
      " 'resnetv2_50x1_bit.goog_in21k_ft_in1k',\n",
      " 'resnetv2_50x3_bit.goog_in21k',\n",
      " 'resnetv2_50x3_bit.goog_in21k_ft_in1k',\n",
      " 'resnetv2_101.a1h_in1k',\n",
      " 'resnetv2_101x1_bit.goog_in21k',\n",
      " 'resnetv2_101x1_bit.goog_in21k_ft_in1k',\n",
      " 'resnetv2_101x3_bit.goog_in21k',\n",
      " 'resnetv2_101x3_bit.goog_in21k_ft_in1k',\n",
      " 'resnetv2_152x2_bit.goog_in21k',\n",
      " 'resnetv2_152x2_bit.goog_in21k_ft_in1k',\n",
      " 'resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k',\n",
      " 'resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384',\n",
      " 'resnetv2_152x4_bit.goog_in21k',\n",
      " 'resnetv2_152x4_bit.goog_in21k_ft_in1k',\n",
      " 'resnext26ts.ra2_in1k',\n",
      " 'resnext50_32x4d.a1_in1k',\n",
      " 'resnext50_32x4d.a1h_in1k',\n",
      " 'resnext50_32x4d.a2_in1k',\n",
      " 'resnext50_32x4d.a3_in1k',\n",
      " 'resnext50_32x4d.fb_ssl_yfcc100m_ft_in1k',\n",
      " 'resnext50_32x4d.fb_swsl_ig1b_ft_in1k',\n",
      " 'resnext50_32x4d.gluon_in1k',\n",
      " 'resnext50_32x4d.ra_in1k',\n",
      " 'resnext50_32x4d.tv2_in1k',\n",
      " 'resnext50_32x4d.tv_in1k',\n",
      " 'resnext50d_32x4d.bt_in1k',\n",
      " 'resnext101_32x4d.fb_ssl_yfcc100m_ft_in1k',\n",
      " 'resnext101_32x4d.fb_swsl_ig1b_ft_in1k',\n",
      " 'resnext101_32x4d.gluon_in1k',\n",
      " 'resnext101_32x8d.fb_ssl_yfcc100m_ft_in1k',\n",
      " 'resnext101_32x8d.fb_swsl_ig1b_ft_in1k',\n",
      " 'resnext101_32x8d.fb_wsl_ig1b_ft_in1k',\n",
      " 'resnext101_32x8d.tv2_in1k',\n",
      " 'resnext101_32x8d.tv_in1k',\n",
      " 'resnext101_32x16d.fb_ssl_yfcc100m_ft_in1k',\n",
      " 'resnext101_32x16d.fb_swsl_ig1b_ft_in1k',\n",
      " 'resnext101_32x16d.fb_wsl_ig1b_ft_in1k',\n",
      " 'resnext101_32x32d.fb_wsl_ig1b_ft_in1k',\n",
      " 'resnext101_64x4d.c1_in1k',\n",
      " 'resnext101_64x4d.gluon_in1k',\n",
      " 'resnext101_64x4d.tv_in1k',\n",
      " 'rexnet_100.nav_in1k',\n",
      " 'rexnet_130.nav_in1k',\n",
      " 'rexnet_150.nav_in1k',\n",
      " 'rexnet_200.nav_in1k',\n",
      " 'rexnet_300.nav_in1k',\n",
      " 'rexnetr_200.sw_in12k',\n",
      " 'rexnetr_200.sw_in12k_ft_in1k',\n",
      " 'rexnetr_300.sw_in12k',\n",
      " 'rexnetr_300.sw_in12k_ft_in1k',\n",
      " 'sebotnet33ts_256.a1h_in1k',\n",
      " 'sehalonet33ts.ra2_in1k',\n",
      " 'SelecSls42b.in1k',\n",
      " 'SelecSls60.in1k',\n",
      " 'SelecSls60b.in1k',\n",
      " 'semnasnet_075.rmsp_in1k',\n",
      " 'semnasnet_100.rmsp_in1k',\n",
      " 'senet154.gluon_in1k',\n",
      " 'sequencer2d_l.in1k',\n",
      " 'sequencer2d_m.in1k',\n",
      " 'sequencer2d_s.in1k',\n",
      " 'seresnet33ts.ra2_in1k',\n",
      " 'seresnet50.a1_in1k',\n",
      " 'seresnet50.a2_in1k',\n",
      " 'seresnet50.a3_in1k',\n",
      " 'seresnet50.ra2_in1k',\n",
      " 'seresnet152d.ra2_in1k',\n",
      " 'seresnext26d_32x4d.bt_in1k',\n",
      " 'seresnext26t_32x4d.bt_in1k',\n",
      " 'seresnext26ts.ch_in1k',\n",
      " 'seresnext50_32x4d.gluon_in1k',\n",
      " 'seresnext50_32x4d.racm_in1k',\n",
      " 'seresnext101_32x4d.gluon_in1k',\n",
      " 'seresnext101_32x8d.ah_in1k',\n",
      " 'seresnext101_64x4d.gluon_in1k',\n",
      " 'seresnext101d_32x8d.ah_in1k',\n",
      " 'seresnextaa101d_32x8d.ah_in1k',\n",
      " 'seresnextaa101d_32x8d.sw_in12k',\n",
      " 'seresnextaa101d_32x8d.sw_in12k_ft_in1k',\n",
      " 'seresnextaa101d_32x8d.sw_in12k_ft_in1k_288',\n",
      " 'skresnet18.ra_in1k',\n",
      " 'skresnet34.ra_in1k',\n",
      " 'skresnext50_32x4d.ra_in1k',\n",
      " 'spnasnet_100.rmsp_in1k',\n",
      " 'swin_base_patch4_window7_224.ms_in1k',\n",
      " 'swin_base_patch4_window7_224.ms_in22k',\n",
      " 'swin_base_patch4_window7_224.ms_in22k_ft_in1k',\n",
      " 'swin_base_patch4_window12_384.ms_in1k',\n",
      " 'swin_base_patch4_window12_384.ms_in22k',\n",
      " 'swin_base_patch4_window12_384.ms_in22k_ft_in1k',\n",
      " 'swin_large_patch4_window7_224.ms_in22k',\n",
      " 'swin_large_patch4_window7_224.ms_in22k_ft_in1k',\n",
      " 'swin_large_patch4_window12_384.ms_in22k',\n",
      " 'swin_large_patch4_window12_384.ms_in22k_ft_in1k',\n",
      " 'swin_s3_base_224.ms_in1k',\n",
      " 'swin_s3_small_224.ms_in1k',\n",
      " 'swin_s3_tiny_224.ms_in1k',\n",
      " 'swin_small_patch4_window7_224.ms_in1k',\n",
      " 'swin_small_patch4_window7_224.ms_in22k',\n",
      " 'swin_small_patch4_window7_224.ms_in22k_ft_in1k',\n",
      " 'swin_tiny_patch4_window7_224.ms_in1k',\n",
      " 'swin_tiny_patch4_window7_224.ms_in22k',\n",
      " 'swin_tiny_patch4_window7_224.ms_in22k_ft_in1k',\n",
      " 'swinv2_base_window8_256.ms_in1k',\n",
      " 'swinv2_base_window12_192.ms_in22k',\n",
      " 'swinv2_base_window12to16_192to256.ms_in22k_ft_in1k',\n",
      " 'swinv2_base_window12to24_192to384.ms_in22k_ft_in1k',\n",
      " 'swinv2_base_window16_256.ms_in1k',\n",
      " 'swinv2_cr_small_224.sw_in1k',\n",
      " 'swinv2_cr_small_ns_224.sw_in1k',\n",
      " 'swinv2_cr_tiny_ns_224.sw_in1k',\n",
      " 'swinv2_large_window12_192.ms_in22k',\n",
      " 'swinv2_large_window12to16_192to256.ms_in22k_ft_in1k',\n",
      " 'swinv2_large_window12to24_192to384.ms_in22k_ft_in1k',\n",
      " 'swinv2_small_window8_256.ms_in1k',\n",
      " 'swinv2_small_window16_256.ms_in1k',\n",
      " 'swinv2_tiny_window8_256.ms_in1k',\n",
      " 'swinv2_tiny_window16_256.ms_in1k',\n",
      " 'tf_efficientnet_b0.aa_in1k',\n",
      " 'tf_efficientnet_b0.ap_in1k',\n",
      " 'tf_efficientnet_b0.in1k',\n",
      " 'tf_efficientnet_b0.ns_jft_in1k',\n",
      " 'tf_efficientnet_b1.aa_in1k',\n",
      " 'tf_efficientnet_b1.ap_in1k',\n",
      " 'tf_efficientnet_b1.in1k',\n",
      " 'tf_efficientnet_b1.ns_jft_in1k',\n",
      " 'tf_efficientnet_b2.aa_in1k',\n",
      " 'tf_efficientnet_b2.ap_in1k',\n",
      " 'tf_efficientnet_b2.in1k',\n",
      " 'tf_efficientnet_b2.ns_jft_in1k',\n",
      " 'tf_efficientnet_b3.aa_in1k',\n",
      " 'tf_efficientnet_b3.ap_in1k',\n",
      " 'tf_efficientnet_b3.in1k',\n",
      " 'tf_efficientnet_b3.ns_jft_in1k',\n",
      " 'tf_efficientnet_b4.aa_in1k',\n",
      " 'tf_efficientnet_b4.ap_in1k',\n",
      " 'tf_efficientnet_b4.in1k',\n",
      " 'tf_efficientnet_b4.ns_jft_in1k',\n",
      " 'tf_efficientnet_b5.aa_in1k',\n",
      " 'tf_efficientnet_b5.ap_in1k',\n",
      " 'tf_efficientnet_b5.in1k',\n",
      " 'tf_efficientnet_b5.ns_jft_in1k',\n",
      " 'tf_efficientnet_b5.ra_in1k',\n",
      " 'tf_efficientnet_b6.aa_in1k',\n",
      " 'tf_efficientnet_b6.ap_in1k',\n",
      " 'tf_efficientnet_b6.ns_jft_in1k',\n",
      " 'tf_efficientnet_b7.aa_in1k',\n",
      " 'tf_efficientnet_b7.ap_in1k',\n",
      " 'tf_efficientnet_b7.ns_jft_in1k',\n",
      " 'tf_efficientnet_b7.ra_in1k',\n",
      " 'tf_efficientnet_b8.ap_in1k',\n",
      " 'tf_efficientnet_b8.ra_in1k',\n",
      " 'tf_efficientnet_cc_b0_4e.in1k',\n",
      " 'tf_efficientnet_cc_b0_8e.in1k',\n",
      " 'tf_efficientnet_cc_b1_8e.in1k',\n",
      " 'tf_efficientnet_el.in1k',\n",
      " 'tf_efficientnet_em.in1k',\n",
      " 'tf_efficientnet_es.in1k',\n",
      " 'tf_efficientnet_l2.ns_jft_in1k',\n",
      " 'tf_efficientnet_l2.ns_jft_in1k_475',\n",
      " 'tf_efficientnet_lite0.in1k',\n",
      " 'tf_efficientnet_lite1.in1k',\n",
      " 'tf_efficientnet_lite2.in1k',\n",
      " 'tf_efficientnet_lite3.in1k',\n",
      " 'tf_efficientnet_lite4.in1k',\n",
      " 'tf_efficientnetv2_b0.in1k',\n",
      " 'tf_efficientnetv2_b1.in1k',\n",
      " 'tf_efficientnetv2_b2.in1k',\n",
      " 'tf_efficientnetv2_b3.in1k',\n",
      " 'tf_efficientnetv2_b3.in21k',\n",
      " 'tf_efficientnetv2_b3.in21k_ft_in1k',\n",
      " 'tf_efficientnetv2_l.in1k',\n",
      " 'tf_efficientnetv2_l.in21k',\n",
      " 'tf_efficientnetv2_l.in21k_ft_in1k',\n",
      " 'tf_efficientnetv2_m.in1k',\n",
      " 'tf_efficientnetv2_m.in21k',\n",
      " 'tf_efficientnetv2_m.in21k_ft_in1k',\n",
      " 'tf_efficientnetv2_s.in1k',\n",
      " 'tf_efficientnetv2_s.in21k',\n",
      " 'tf_efficientnetv2_s.in21k_ft_in1k',\n",
      " 'tf_efficientnetv2_xl.in21k',\n",
      " 'tf_efficientnetv2_xl.in21k_ft_in1k',\n",
      " 'tf_mixnet_l.in1k',\n",
      " 'tf_mixnet_m.in1k',\n",
      " 'tf_mixnet_s.in1k',\n",
      " 'tf_mobilenetv3_large_075.in1k',\n",
      " 'tf_mobilenetv3_large_100.in1k',\n",
      " 'tf_mobilenetv3_large_minimal_100.in1k',\n",
      " 'tf_mobilenetv3_small_075.in1k',\n",
      " 'tf_mobilenetv3_small_100.in1k',\n",
      " 'tf_mobilenetv3_small_minimal_100.in1k',\n",
      " 'tinynet_a.in1k',\n",
      " 'tinynet_b.in1k',\n",
      " 'tinynet_c.in1k',\n",
      " 'tinynet_d.in1k',\n",
      " 'tinynet_e.in1k',\n",
      " 'tnt_s_patch16_224',\n",
      " 'tresnet_l.miil_in1k',\n",
      " 'tresnet_l.miil_in1k_448',\n",
      " 'tresnet_m.miil_in1k',\n",
      " 'tresnet_m.miil_in1k_448',\n",
      " 'tresnet_m.miil_in21k',\n",
      " 'tresnet_m.miil_in21k_ft_in1k',\n",
      " 'tresnet_v2_l.miil_in21k',\n",
      " 'tresnet_v2_l.miil_in21k_ft_in1k',\n",
      " 'tresnet_xl.miil_in1k',\n",
      " 'tresnet_xl.miil_in1k_448',\n",
      " 'twins_pcpvt_base.in1k',\n",
      " 'twins_pcpvt_large.in1k',\n",
      " 'twins_pcpvt_small.in1k',\n",
      " 'twins_svt_base.in1k',\n",
      " 'twins_svt_large.in1k',\n",
      " 'twins_svt_small.in1k',\n",
      " 'vgg11.tv_in1k',\n",
      " 'vgg11_bn.tv_in1k',\n",
      " 'vgg13.tv_in1k',\n",
      " 'vgg13_bn.tv_in1k',\n",
      " 'vgg16.tv_in1k',\n",
      " 'vgg16_bn.tv_in1k',\n",
      " 'vgg19.tv_in1k',\n",
      " 'vgg19_bn.tv_in1k',\n",
      " 'visformer_small.in1k',\n",
      " 'visformer_tiny.in1k',\n",
      " 'vit_base_patch8_224.augreg2_in21k_ft_in1k',\n",
      " 'vit_base_patch8_224.augreg_in21k',\n",
      " 'vit_base_patch8_224.augreg_in21k_ft_in1k',\n",
      " 'vit_base_patch8_224.dino',\n",
      " 'vit_base_patch14_dinov2.lvd142m',\n",
      " 'vit_base_patch16_224.augreg2_in21k_ft_in1k',\n",
      " 'vit_base_patch16_224.augreg_in1k',\n",
      " 'vit_base_patch16_224.augreg_in21k',\n",
      " 'vit_base_patch16_224.augreg_in21k_ft_in1k',\n",
      " 'vit_base_patch16_224.dino',\n",
      " 'vit_base_patch16_224.mae',\n",
      " 'vit_base_patch16_224.orig_in21k_ft_in1k',\n",
      " 'vit_base_patch16_224.sam_in1k',\n",
      " 'vit_base_patch16_224_miil.in21k',\n",
      " 'vit_base_patch16_224_miil.in21k_ft_in1k',\n",
      " 'vit_base_patch16_384.augreg_in1k',\n",
      " 'vit_base_patch16_384.augreg_in21k_ft_in1k',\n",
      " 'vit_base_patch16_384.orig_in21k_ft_in1k',\n",
      " 'vit_base_patch16_clip_224.laion2b',\n",
      " 'vit_base_patch16_clip_224.laion2b_ft_in1k',\n",
      " 'vit_base_patch16_clip_224.laion2b_ft_in12k',\n",
      " 'vit_base_patch16_clip_224.laion2b_ft_in12k_in1k',\n",
      " 'vit_base_patch16_clip_224.openai',\n",
      " 'vit_base_patch16_clip_224.openai_ft_in1k',\n",
      " 'vit_base_patch16_clip_224.openai_ft_in12k',\n",
      " 'vit_base_patch16_clip_224.openai_ft_in12k_in1k',\n",
      " 'vit_base_patch16_clip_384.laion2b_ft_in1k',\n",
      " 'vit_base_patch16_clip_384.laion2b_ft_in12k_in1k',\n",
      " 'vit_base_patch16_clip_384.openai_ft_in1k',\n",
      " 'vit_base_patch16_clip_384.openai_ft_in12k_in1k',\n",
      " 'vit_base_patch16_rpn_224.sw_in1k',\n",
      " 'vit_base_patch32_224.augreg_in1k',\n",
      " 'vit_base_patch32_224.augreg_in21k',\n",
      " 'vit_base_patch32_224.augreg_in21k_ft_in1k',\n",
      " 'vit_base_patch32_224.sam_in1k',\n",
      " 'vit_base_patch32_384.augreg_in1k',\n",
      " 'vit_base_patch32_384.augreg_in21k_ft_in1k',\n",
      " 'vit_base_patch32_clip_224.laion2b',\n",
      " 'vit_base_patch32_clip_224.laion2b_ft_in1k',\n",
      " 'vit_base_patch32_clip_224.laion2b_ft_in12k_in1k',\n",
      " 'vit_base_patch32_clip_224.openai',\n",
      " 'vit_base_patch32_clip_224.openai_ft_in1k',\n",
      " 'vit_base_patch32_clip_384.laion2b_ft_in12k_in1k',\n",
      " 'vit_base_patch32_clip_384.openai_ft_in12k_in1k',\n",
      " 'vit_base_patch32_clip_448.laion2b_ft_in12k_in1k',\n",
      " 'vit_base_r50_s16_224.orig_in21k',\n",
      " 'vit_base_r50_s16_384.orig_in21k_ft_in1k',\n",
      " 'vit_giant_patch14_clip_224.laion2b',\n",
      " 'vit_giant_patch14_dinov2.lvd142m',\n",
      " 'vit_gigantic_patch14_clip_224.laion2b',\n",
      " 'vit_huge_patch14_224.mae',\n",
      " 'vit_huge_patch14_224.orig_in21k',\n",
      " 'vit_huge_patch14_clip_224.laion2b',\n",
      " 'vit_huge_patch14_clip_224.laion2b_ft_in1k',\n",
      " 'vit_huge_patch14_clip_224.laion2b_ft_in12k',\n",
      " 'vit_huge_patch14_clip_224.laion2b_ft_in12k_in1k',\n",
      " 'vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k',\n",
      " 'vit_large_patch14_clip_224.datacompxl',\n",
      " 'vit_large_patch14_clip_224.laion2b',\n",
      " 'vit_large_patch14_clip_224.laion2b_ft_in1k',\n",
      " 'vit_large_patch14_clip_224.laion2b_ft_in12k',\n",
      " 'vit_large_patch14_clip_224.laion2b_ft_in12k_in1k',\n",
      " 'vit_large_patch14_clip_224.openai',\n",
      " 'vit_large_patch14_clip_224.openai_ft_in1k',\n",
      " 'vit_large_patch14_clip_224.openai_ft_in12k',\n",
      " 'vit_large_patch14_clip_224.openai_ft_in12k_in1k',\n",
      " 'vit_large_patch14_clip_336.laion2b_ft_in1k',\n",
      " 'vit_large_patch14_clip_336.laion2b_ft_in12k_in1k',\n",
      " 'vit_large_patch14_clip_336.openai',\n",
      " 'vit_large_patch14_clip_336.openai_ft_in12k_in1k',\n",
      " 'vit_large_patch14_dinov2.lvd142m',\n",
      " 'vit_large_patch16_224.augreg_in21k',\n",
      " 'vit_large_patch16_224.augreg_in21k_ft_in1k',\n",
      " 'vit_large_patch16_224.mae',\n",
      " 'vit_large_patch16_384.augreg_in21k_ft_in1k',\n",
      " 'vit_large_patch32_224.orig_in21k',\n",
      " 'vit_large_patch32_384.orig_in21k_ft_in1k',\n",
      " 'vit_large_r50_s32_224.augreg_in21k',\n",
      " 'vit_large_r50_s32_224.augreg_in21k_ft_in1k',\n",
      " 'vit_large_r50_s32_384.augreg_in21k_ft_in1k',\n",
      " 'vit_medium_patch16_gap_240.sw_in12k',\n",
      " 'vit_medium_patch16_gap_256.sw_in12k_ft_in1k',\n",
      " 'vit_medium_patch16_gap_384.sw_in12k_ft_in1k',\n",
      " 'vit_relpos_base_patch16_224.sw_in1k',\n",
      " 'vit_relpos_base_patch16_clsgap_224.sw_in1k',\n",
      " 'vit_relpos_base_patch32_plus_rpn_256.sw_in1k',\n",
      " 'vit_relpos_medium_patch16_224.sw_in1k',\n",
      " 'vit_relpos_medium_patch16_cls_224.sw_in1k',\n",
      " 'vit_relpos_medium_patch16_rpn_224.sw_in1k',\n",
      " 'vit_relpos_small_patch16_224.sw_in1k',\n",
      " 'vit_small_patch8_224.dino',\n",
      " 'vit_small_patch14_dinov2.lvd142m',\n",
      " 'vit_small_patch16_224.augreg_in1k',\n",
      " 'vit_small_patch16_224.augreg_in21k',\n",
      " 'vit_small_patch16_224.augreg_in21k_ft_in1k',\n",
      " 'vit_small_patch16_224.dino',\n",
      " 'vit_small_patch16_384.augreg_in1k',\n",
      " 'vit_small_patch16_384.augreg_in21k_ft_in1k',\n",
      " 'vit_small_patch32_224.augreg_in21k',\n",
      " 'vit_small_patch32_224.augreg_in21k_ft_in1k',\n",
      " 'vit_small_patch32_384.augreg_in21k_ft_in1k',\n",
      " 'vit_small_r26_s32_224.augreg_in21k',\n",
      " 'vit_small_r26_s32_224.augreg_in21k_ft_in1k',\n",
      " 'vit_small_r26_s32_384.augreg_in21k_ft_in1k',\n",
      " 'vit_srelpos_medium_patch16_224.sw_in1k',\n",
      " 'vit_srelpos_small_patch16_224.sw_in1k',\n",
      " 'vit_tiny_patch16_224.augreg_in21k',\n",
      " 'vit_tiny_patch16_224.augreg_in21k_ft_in1k',\n",
      " 'vit_tiny_patch16_384.augreg_in21k_ft_in1k',\n",
      " 'vit_tiny_r_s16_p8_224.augreg_in21k',\n",
      " 'vit_tiny_r_s16_p8_224.augreg_in21k_ft_in1k',\n",
      " 'vit_tiny_r_s16_p8_384.augreg_in21k_ft_in1k',\n",
      " 'volo_d1_224.sail_in1k',\n",
      " 'volo_d1_384.sail_in1k',\n",
      " 'volo_d2_224.sail_in1k',\n",
      " 'volo_d2_384.sail_in1k',\n",
      " 'volo_d3_224.sail_in1k',\n",
      " 'volo_d3_448.sail_in1k',\n",
      " 'volo_d4_224.sail_in1k',\n",
      " 'volo_d4_448.sail_in1k',\n",
      " 'volo_d5_224.sail_in1k',\n",
      " 'volo_d5_448.sail_in1k',\n",
      " 'volo_d5_512.sail_in1k',\n",
      " 'wide_resnet50_2.racm_in1k',\n",
      " 'wide_resnet50_2.tv2_in1k',\n",
      " 'wide_resnet50_2.tv_in1k',\n",
      " 'wide_resnet101_2.tv2_in1k',\n",
      " 'wide_resnet101_2.tv_in1k',\n",
      " 'xception41.tf_in1k',\n",
      " 'xception41p.ra3_in1k',\n",
      " 'xception65.ra3_in1k',\n",
      " 'xception65.tf_in1k',\n",
      " 'xception65p.ra3_in1k',\n",
      " 'xception71.tf_in1k',\n",
      " 'xcit_large_24_p8_224.fb_dist_in1k',\n",
      " 'xcit_large_24_p8_224.fb_in1k',\n",
      " 'xcit_large_24_p8_384.fb_dist_in1k',\n",
      " 'xcit_large_24_p16_224.fb_dist_in1k',\n",
      " 'xcit_large_24_p16_224.fb_in1k',\n",
      " 'xcit_large_24_p16_384.fb_dist_in1k',\n",
      " 'xcit_medium_24_p8_224.fb_dist_in1k',\n",
      " 'xcit_medium_24_p8_224.fb_in1k',\n",
      " 'xcit_medium_24_p8_384.fb_dist_in1k',\n",
      " 'xcit_medium_24_p16_224.fb_dist_in1k',\n",
      " 'xcit_medium_24_p16_224.fb_in1k',\n",
      " 'xcit_medium_24_p16_384.fb_dist_in1k',\n",
      " 'xcit_nano_12_p8_224.fb_dist_in1k',\n",
      " 'xcit_nano_12_p8_224.fb_in1k',\n",
      " 'xcit_nano_12_p8_384.fb_dist_in1k',\n",
      " 'xcit_nano_12_p16_224.fb_dist_in1k',\n",
      " 'xcit_nano_12_p16_224.fb_in1k',\n",
      " 'xcit_nano_12_p16_384.fb_dist_in1k',\n",
      " 'xcit_small_12_p8_224.fb_dist_in1k',\n",
      " 'xcit_small_12_p8_224.fb_in1k',\n",
      " 'xcit_small_12_p8_384.fb_dist_in1k',\n",
      " 'xcit_small_12_p16_224.fb_dist_in1k',\n",
      " 'xcit_small_12_p16_224.fb_in1k',\n",
      " 'xcit_small_12_p16_384.fb_dist_in1k',\n",
      " 'xcit_small_24_p8_224.fb_dist_in1k',\n",
      " 'xcit_small_24_p8_224.fb_in1k',\n",
      " 'xcit_small_24_p8_384.fb_dist_in1k',\n",
      " 'xcit_small_24_p16_224.fb_dist_in1k',\n",
      " 'xcit_small_24_p16_224.fb_in1k',\n",
      " 'xcit_small_24_p16_384.fb_dist_in1k',\n",
      " 'xcit_tiny_12_p8_224.fb_dist_in1k',\n",
      " 'xcit_tiny_12_p8_224.fb_in1k',\n",
      " 'xcit_tiny_12_p8_384.fb_dist_in1k',\n",
      " 'xcit_tiny_12_p16_224.fb_dist_in1k',\n",
      " 'xcit_tiny_12_p16_224.fb_in1k',\n",
      " 'xcit_tiny_12_p16_384.fb_dist_in1k',\n",
      " 'xcit_tiny_24_p8_224.fb_dist_in1k',\n",
      " 'xcit_tiny_24_p8_224.fb_in1k',\n",
      " 'xcit_tiny_24_p8_384.fb_dist_in1k',\n",
      " 'xcit_tiny_24_p16_224.fb_dist_in1k',\n",
      " 'xcit_tiny_24_p16_224.fb_in1k',\n",
      " 'xcit_tiny_24_p16_384.fb_dist_in1k']\n"
     ]
    }
   ],
   "source": [
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    print(\"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
    "    os.remove('tmp.pt')\n",
    "    \n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint.pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6703a4e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T03:32:22.934912Z",
     "start_time": "2023-06-05T03:32:22.171553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('resnet18', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e91650a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T03:32:24.547315Z",
     "start_time": "2023-06-05T03:32:24.525603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    category=DeprecationWarning,\n",
    "    module=r'.*'\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    action='default',\n",
    "    module=r'torch.ao.quantization'\n",
    ")\n",
    "\n",
    "# Specify random seed for repeatable results\n",
    "_ = torch.manual_seed(191009)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "    \n",
    "def print_size_of_model(model):\n",
    "    if isinstance(model, torch.jit.RecursiveScriptModule):\n",
    "        torch.jit.save(model, \"temp.p\")\n",
    "    else:\n",
    "        torch.jit.save(torch.jit.script(model), \"temp.p\")\n",
    "    print(\"Size (MB):\", os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove(\"temp.p\")\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for image, target in data_loader:\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "            cnt += 1\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            top1.update(acc1[0], image.size(0))\n",
    "            top5.update(acc5[0], image.size(0))\n",
    "    print('')\n",
    "\n",
    "    return top1, top5\n",
    "\n",
    "\n",
    "def prepare_data_loaders(data_path):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    dataset = torchvision.datasets.ImageNet(\n",
    "        data_path, split=\"train\", transform=transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    dataset_test = torchvision.datasets.ImageNet(\n",
    "        data_path, split=\"val\", transform=transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "    train_sampler = torch.utils.data.RandomSampler(dataset)\n",
    "    test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=train_batch_size,\n",
    "        sampler=train_sampler)\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=eval_batch_size,\n",
    "        sampler=test_sampler)\n",
    "\n",
    "    return data_loader, data_loader_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c860d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T03:32:28.887955Z",
     "start_time": "2023-06-05T03:32:28.880949Z"
    }
   },
   "outputs": [],
   "source": [
    "qconfig = get_default_qconfig(\"x86\")\n",
    "qconfig_mapping = QConfigMapping().set_global(qconfig)\n",
    "# qconfig_mapping = (QConfigMapping()\n",
    "#     .set_global(qconfig_opt)  # qconfig_opt is an optional qconfig, either a valid qconfig or None\n",
    "#     .set_object_type(torch.nn.Conv2d, qconfig_opt) # can be a callable...\n",
    "#     .set_object_type(\"torch.nn.functional.add\", qconfig_opt) # ...or a string of the class name\n",
    "#     .set_module_name_regex(\"foo.*bar.*conv[0-9]+\", qconfig_opt) # matched in order, first match takes precedence\n",
    "#     .set_module_name(\"foo.bar\", qconfig_opt)\n",
    "#     .set_module_name_object_type_order()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a20d4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T10:04:04.290607Z",
     "start_time": "2023-06-02T10:04:01.597318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.5082, -0.3883, -0.4226,  ...,  0.9303,  0.3823,  0.6392],\n",
       "          [-0.6281, -0.6965, -0.4397,  ...,  0.8104,  0.5878,  0.2111],\n",
       "          [-0.5767, -0.1486,  0.0741,  ...,  0.7419,  0.8961,  0.2282],\n",
       "          ...,\n",
       "          [-0.3369, -0.3883, -0.3541,  ..., -0.0629, -0.2856, -0.4226],\n",
       "          [-0.2856, -0.3198, -0.3369,  ..., -0.4568,  0.1083,  0.5364],\n",
       "          [-0.2342, -0.2513, -0.1657,  ..., -0.2684, -0.3369, -0.3198]],\n",
       "\n",
       "         [[-0.5651, -0.4076, -0.0399,  ...,  1.2731,  0.7479,  1.0280],\n",
       "          [-0.5301, -0.6352, -0.3550,  ...,  1.1331,  0.8880,  0.5378],\n",
       "          [-0.4426, -0.0924,  0.1176,  ...,  1.0805,  1.2906,  0.6604],\n",
       "          ...,\n",
       "          [-0.1625, -0.2500, -0.2325,  ...,  0.0476, -0.0924, -0.0399],\n",
       "          [ 0.0826, -0.1099, -0.2325,  ..., -0.0924,  0.4153,  0.9580],\n",
       "          [ 0.6604,  0.3452,  0.3627,  ...,  0.1176, -0.0749, -0.1450]],\n",
       "\n",
       "         [[-0.7413, -0.5495,  0.0779,  ...,  1.0888,  0.7576,  0.7054],\n",
       "          [-0.8110, -0.7936, -0.4450,  ...,  1.1934,  1.0191,  0.6705],\n",
       "          [-0.7936, -0.4275, -0.1312,  ...,  1.0365,  1.3328,  0.7228],\n",
       "          ...,\n",
       "          [-0.2358, -0.2881, -0.2184,  ...,  0.0082, -0.2010, -0.2532],\n",
       "          [ 0.1999, -0.0790, -0.2010,  ..., -0.2184,  0.4962,  1.1411],\n",
       "          [ 0.9319,  0.6705,  0.5834,  ...,  0.3219, -0.1138, -0.3230]]],\n",
       "\n",
       "\n",
       "        [[[-1.4329, -1.7583, -1.6898,  ..., -1.6898, -1.7069, -1.6727],\n",
       "          [-1.6042, -1.7754, -1.7583,  ..., -1.5357, -1.6384, -1.7412],\n",
       "          [-1.6727, -1.9124, -1.8782,  ..., -1.4329, -1.4329, -1.4158],\n",
       "          ...,\n",
       "          [-0.2513, -0.1486, -0.2342,  ..., -1.4329, -1.4158, -1.3473],\n",
       "          [-0.2684, -0.1999, -0.2684,  ..., -1.6213, -1.6384, -1.5699],\n",
       "          [-0.3198, -0.3027, -0.3198,  ..., -1.6213, -1.6042, -1.6384]],\n",
       "\n",
       "         [[-1.1078, -1.4055, -1.4230,  ..., -1.1954, -1.2304, -1.2129],\n",
       "          [-1.2829, -1.4755, -1.5280,  ..., -1.3354, -1.4230, -1.5280],\n",
       "          [-1.4580, -1.7381, -1.7731,  ..., -1.2479, -1.2129, -1.2129],\n",
       "          ...,\n",
       "          [-0.0749,  0.0301, -0.0224,  ..., -1.2829, -1.2479, -1.0903],\n",
       "          [-0.1275, -0.0749, -0.0924,  ..., -1.2479, -1.2829, -1.2829],\n",
       "          [-0.1625, -0.1800, -0.1625,  ..., -1.2829, -1.3004, -1.3704]],\n",
       "\n",
       "         [[-0.4973, -0.7936, -0.8981,  ..., -1.2990, -1.3164, -1.2641],\n",
       "          [-0.8633, -1.0201, -1.1073,  ..., -1.1944, -1.2990, -1.3861],\n",
       "          [-1.1073, -1.3861, -1.4210,  ..., -1.0201, -1.0376, -1.0550],\n",
       "          ...,\n",
       "          [-0.2707, -0.1835, -0.2881,  ..., -0.8458, -0.8110, -0.7587],\n",
       "          [-0.2881, -0.2532, -0.2707,  ..., -0.7587, -0.7936, -0.8284],\n",
       "          [-0.3230, -0.3404, -0.3055,  ..., -0.8110, -0.8284, -0.9156]]],\n",
       "\n",
       "\n",
       "        [[[-1.9467, -0.9877, -0.5596,  ..., -0.0287,  0.0569, -0.6281],\n",
       "          [-1.8439, -1.5185, -1.8953,  ...,  0.3138,  0.1597, -0.2856],\n",
       "          [-1.7925, -1.9809, -2.0494,  ..., -0.8507, -1.1075, -0.3198],\n",
       "          ...,\n",
       "          [ 1.1187,  1.4783,  1.7180,  ..., -1.9809, -1.9638, -1.9809],\n",
       "          [ 1.3927,  1.7180,  1.7009,  ..., -1.9980, -1.9809, -1.9980],\n",
       "          [ 1.4783,  1.4783,  0.6221,  ..., -1.9638, -1.9809, -1.9809]],\n",
       "\n",
       "         [[-1.3004, -0.6702, -0.3550,  ...,  0.7304,  0.8354,  0.1001],\n",
       "          [-1.2129, -1.1604, -1.7906,  ...,  1.1155,  0.9055,  0.5028],\n",
       "          [-1.2304, -1.7556, -1.9482,  ..., -0.0749, -0.4776,  0.3627],\n",
       "          ...,\n",
       "          [ 0.7829,  1.5007,  1.6232,  ..., -1.8081, -1.7906, -1.8081],\n",
       "          [ 1.1155,  1.7108,  1.7108,  ..., -1.8256, -1.8081, -1.8256],\n",
       "          [ 1.1681,  1.1506,  0.4853,  ..., -1.7906, -1.8081, -1.8081]],\n",
       "\n",
       "         [[-1.6824, -1.1944, -0.9156,  ..., -0.5321, -0.5321, -0.8458],\n",
       "          [-1.7173, -1.4210, -1.6127,  ..., -0.0964, -0.2532, -0.4798],\n",
       "          [-1.6650, -1.6824, -1.6824,  ..., -1.0376, -1.0201, -0.4101],\n",
       "          ...,\n",
       "          [ 0.1128,  0.6879,  0.9319,  ..., -1.5256, -1.5081, -1.5081],\n",
       "          [ 0.8099,  1.1585,  0.9494,  ..., -1.5430, -1.5256, -1.5256],\n",
       "          [ 0.6879,  0.5311, -0.0615,  ..., -1.5430, -1.5430, -1.5081]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.0048, -1.3130, -1.3302,  ..., -1.1589, -1.1075,  0.3309],\n",
       "          [-1.1247, -1.1418, -1.1247,  ..., -1.3987, -0.4568,  0.7248],\n",
       "          [-0.7137, -1.1932, -1.4158,  ..., -0.8678, -0.6794, -0.4911],\n",
       "          ...,\n",
       "          [-0.0629, -0.1657,  0.7077,  ...,  0.0227,  0.2967,  0.2111],\n",
       "          [ 0.0912,  0.1254,  0.5364,  ...,  0.1597,  0.2282,  0.1597],\n",
       "          [ 0.1768,  0.2282,  0.1597,  ...,  0.1939, -0.1486,  0.1254]],\n",
       "\n",
       "         [[-0.2850, -0.6702, -0.6176,  ..., -0.3375, -0.1275,  1.2381],\n",
       "          [-0.6702, -0.6527, -0.5476,  ..., -0.7752,  0.4503,  1.3606],\n",
       "          [-0.3025, -0.7752, -0.8452,  ..., -0.1625,  0.1877,  0.5903],\n",
       "          ...,\n",
       "          [-0.3200, -0.1800,  1.1681,  ...,  0.3452,  1.1681,  1.0630],\n",
       "          [ 0.1352,  0.0476,  1.0105,  ...,  0.4503,  0.9230,  1.2206],\n",
       "          [ 0.6254,  0.5728,  0.7654,  ...,  0.7129,  0.5553,  1.1331]],\n",
       "\n",
       "         [[-1.0724, -1.4036, -1.3687,  ..., -1.1770, -0.3578,  1.6988],\n",
       "          [-1.3164, -1.3339, -1.3339,  ..., -1.2467,  0.6531,  1.6640],\n",
       "          [-1.0201, -1.3339, -1.5430,  ..., -0.9853, -0.7761,  0.0256],\n",
       "          ...,\n",
       "          [-0.8110, -0.6367,  0.3393,  ..., -0.4101, -0.3404, -0.3055],\n",
       "          [-0.5844, -0.5321,  0.3045,  ..., -0.3230, -0.4450, -0.3753],\n",
       "          [ 0.0256, -0.0267,  0.1999,  ..., -0.3404, -0.7064, -0.3927]]],\n",
       "\n",
       "\n",
       "        [[[-1.3302, -0.5082, -0.6623,  ...,  1.3584,  1.5297,  1.7352],\n",
       "          [-1.0390, -0.5082, -0.3712,  ...,  1.2728,  1.3413,  1.6667],\n",
       "          [-0.8335,  0.2111, -0.5082,  ...,  1.2385,  1.1358,  0.8789],\n",
       "          ...,\n",
       "          [-1.2274, -1.3130, -1.4329,  ..., -0.5938, -1.0219, -0.5424],\n",
       "          [-1.7069, -1.7240, -1.7754,  ..., -0.8507, -0.8335, -0.9534],\n",
       "          [-1.3815, -1.3815, -1.6042,  ..., -1.0562, -1.0390, -0.9705]],\n",
       "\n",
       "         [[-0.4251,  0.1001,  0.1352,  ...,  2.0609,  2.1485,  2.2010],\n",
       "          [-0.3725, -0.0224,  0.4153,  ...,  1.9909,  2.0434,  2.1660],\n",
       "          [-0.2675,  0.6254,  0.0651,  ...,  1.9734,  1.9734,  1.8158],\n",
       "          ...,\n",
       "          [-0.5651, -0.6527, -0.6176,  ..., -0.0574, -0.1625,  0.4328],\n",
       "          [-1.1779, -1.2829, -1.3179,  ..., -0.1800, -0.3725, -0.1800],\n",
       "          [-0.8627, -0.7927, -0.9503,  ..., -0.4251, -0.4076, -0.1625]],\n",
       "\n",
       "         [[-0.2707,  0.3219,  0.1302,  ...,  1.8034,  1.9428,  2.0997],\n",
       "          [-0.0441,  0.3045,  0.3219,  ...,  1.7860,  1.8557,  2.0474],\n",
       "          [ 0.1302,  0.8274,  0.1651,  ...,  1.7860,  1.8905,  1.7511],\n",
       "          ...,\n",
       "          [-0.4275, -0.4275, -0.3578,  ...,  0.3568, -0.2881,  0.1302],\n",
       "          [-1.0724, -1.1770, -1.1247,  ..., -0.1138, -0.3753, -0.2881],\n",
       "          [-1.0724, -1.0027, -1.1073,  ..., -0.2707, -0.1835, -0.0267]]],\n",
       "\n",
       "\n",
       "        [[[-0.2342, -0.3541, -0.1657,  ..., -0.9192, -1.2959, -1.0733],\n",
       "          [ 0.2796,  0.3138, -0.0116,  ..., -0.9363, -1.1760, -0.7993],\n",
       "          [ 0.6734,  0.3994, -0.1143,  ..., -0.6794, -1.0390, -0.7479],\n",
       "          ...,\n",
       "          [-0.4397, -0.3027, -0.3883,  ..., -0.7137, -0.6109, -0.7650],\n",
       "          [-0.4911, -0.2684, -0.4226,  ..., -0.8335, -0.7993, -0.6109],\n",
       "          [-0.5424, -0.4911, -0.4568,  ..., -0.8678, -1.1247, -0.7993]],\n",
       "\n",
       "         [[ 0.3978,  0.1176,  0.2227,  ..., -0.7927, -1.1604, -0.9678],\n",
       "          [ 0.6954,  0.6954,  0.3978,  ..., -0.7402, -1.0728, -0.6702],\n",
       "          [ 1.0280,  0.8004,  0.2577,  ..., -0.6176, -0.8978, -0.5651],\n",
       "          ...,\n",
       "          [ 0.3627,  0.5028,  0.4328,  ...,  0.1527,  0.2052,  0.0476],\n",
       "          [ 0.3277,  0.5553,  0.4153,  ...,  0.0126,  0.0301,  0.2577],\n",
       "          [ 0.2752,  0.3102,  0.3627,  ..., -0.0399, -0.2150,  0.2577]],\n",
       "\n",
       "         [[ 0.2696,  0.0779,  0.3045,  ..., -0.8458, -1.0550, -0.9330],\n",
       "          [ 0.2696,  0.4265,  0.2173,  ..., -0.7761, -0.8458, -0.6715],\n",
       "          [ 0.5659,  0.5485,  0.1476,  ..., -0.6193, -0.7413, -0.5147],\n",
       "          ...,\n",
       "          [-0.0441,  0.2522,  0.0779,  ..., -0.4101, -0.4450, -0.7936],\n",
       "          [-0.1138,  0.1999,  0.0256,  ..., -0.6541, -0.4798, -0.3055],\n",
       "          [-0.1138, -0.0441, -0.0092,  ..., -0.4973, -0.6018, -0.3578]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '/data1/data/imagenet2012/'\n",
    "train_batch_size = 30\n",
    "eval_batch_size = 50\n",
    "data_loader, data_loader_test = prepare_data_loaders(data_path)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "example_inputs = (next(iter(data_loader_test))[0]) # get an example input\n",
    "example_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b05636fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T10:04:06.168861Z",
     "start_time": "2023-06-02T10:04:04.292711Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wrq/anaconda3/envs/quant/lib/python3.9/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (activation_post_process_0): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (conv1): ConvReLU2d(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (activation_post_process_1): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (activation_post_process_2): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (layer1): Module(\n",
       "    (0): Module(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (activation_post_process_3): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_4): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_5): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_6): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_7): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_8): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_9): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_10): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_11): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_12): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_13): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_14): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (layer2): Module(\n",
       "    (0): Module(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (activation_post_process_15): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_16): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_17): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_18): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_19): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_20): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_21): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_22): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_23): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_24): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_25): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_26): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_27): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (layer3): Module(\n",
       "    (0): Module(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (activation_post_process_28): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_29): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_30): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_31): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_32): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_33): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_34): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_35): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_36): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_37): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_38): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_39): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_40): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (layer4): Module(\n",
       "    (0): Module(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (activation_post_process_41): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_42): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_43): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_44): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_45): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_46): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_47): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_48): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_49): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_50): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_51): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_52): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_53): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (global_pool): Module(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (activation_post_process_54): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_55): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  (activation_post_process_56): HistogramObserver(min_val=inf, max_val=-inf)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_model = prepare_fx(model, qconfig_mapping, example_inputs)  # fuse modules and\n",
    "prepared_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Torch_  import FxGraphDrawer\n",
    "# g = FxGraphDrawer(quantized_model, \"fx_quantize\")\n",
    "# g.get_main_dot_graph().write_svg(\"fx_quantize.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1077c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T10:05:01.981348Z",
     "start_time": "2023-06-02T10:04:06.170739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def calibrate(model, data_loader):\n",
    "    model.eval()\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for image, target in data_loader:\n",
    "            if cnt > 1:\n",
    "                break\n",
    "            print(cnt)\n",
    "            cnt += 1\n",
    "            model(image)\n",
    "calibrate(prepared_model, data_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f20f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T10:07:39.353002Z",
     "start_time": "2023-06-02T10:07:39.082139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (conv1): ConvReLU2d(\n",
      "    (0): QuantizedConv2d(Reference)(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Module(\n",
      "    (0): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Module(\n",
      "    (0): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (downsample): Module(\n",
      "        (0): QuantizedConv2d(Reference)(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "      )\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Module(\n",
      "    (0): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (downsample): Module(\n",
      "        (0): QuantizedConv2d(Reference)(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "      )\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Module(\n",
      "    (0): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (downsample): Module(\n",
      "        (0): QuantizedConv2d(Reference)(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "      )\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): Module(\n",
      "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (fc): QuantizedLinear(Reference)(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.037445519119501114, 57, 0, 127, torch.uint8);  x = None\n",
      "    dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.037445519119501114, 57, 0, 127, torch.uint8);  quantize_per_tensor_default = None\n",
      "    conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None\n",
      "    quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.12883716821670532, 0, 0, 127, torch.uint8);  conv1 = None\n",
      "    dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.12883716821670532, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_1 = None\n",
      "    maxpool = self.maxpool(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None\n",
      "    quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(maxpool, 0.12883716821670532, 0, 0, 127, torch.uint8);  maxpool = None\n",
      "    dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.12883716821670532, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_2 = None\n",
      "    layer1_0_conv1 = getattr(self.layer1, \"0\").conv1(dequantize_per_tensor_default_2)\n",
      "    quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_conv1, 0.13203494250774384, 86, 0, 127, torch.uint8);  layer1_0_conv1 = None\n",
      "    dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.13203494250774384, 86, 0, 127, torch.uint8);  quantize_per_tensor_default_3 = None\n",
      "    layer1_0_drop_block = getattr(self.layer1, \"0\").drop_block(dequantize_per_tensor_default_3);  dequantize_per_tensor_default_3 = None\n",
      "    quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_drop_block, 0.13203494250774384, 86, 0, 127, torch.uint8);  layer1_0_drop_block = None\n",
      "    dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.13203494250774384, 86, 0, 127, torch.uint8);  quantize_per_tensor_default_4 = None\n",
      "    layer1_0_act1 = getattr(self.layer1, \"0\").act1(dequantize_per_tensor_default_4);  dequantize_per_tensor_default_4 = None\n",
      "    quantize_per_tensor_default_5 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_act1, 0.13203494250774384, 86, 0, 127, torch.uint8);  layer1_0_act1 = None\n",
      "    dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_5, 0.13203494250774384, 86, 0, 127, torch.uint8);  quantize_per_tensor_default_5 = None\n",
      "    layer1_0_aa = getattr(self.layer1, \"0\").aa(dequantize_per_tensor_default_5);  dequantize_per_tensor_default_5 = None\n",
      "    quantize_per_tensor_default_6 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_aa, 0.13203494250774384, 86, 0, 127, torch.uint8);  layer1_0_aa = None\n",
      "    dequantize_per_tensor_default_6 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_6, 0.13203494250774384, 86, 0, 127, torch.uint8);  quantize_per_tensor_default_6 = None\n",
      "    layer1_0_conv2 = getattr(self.layer1, \"0\").conv2(dequantize_per_tensor_default_6);  dequantize_per_tensor_default_6 = None\n",
      "    quantize_per_tensor_default_7 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_conv2, 0.2708899974822998, 90, 0, 127, torch.uint8);  layer1_0_conv2 = None\n",
      "    dequantize_per_tensor_default_7 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_7, 0.2708899974822998, 90, 0, 127, torch.uint8);  quantize_per_tensor_default_7 = None\n",
      "    add = dequantize_per_tensor_default_7 + dequantize_per_tensor_default_2;  dequantize_per_tensor_default_7 = dequantize_per_tensor_default_2 = None\n",
      "    layer1_0_act2 = getattr(self.layer1, \"0\").act2(add);  add = None\n",
      "    quantize_per_tensor_default_8 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_act2, 0.1227148175239563, 0, 0, 127, torch.uint8);  layer1_0_act2 = None\n",
      "    dequantize_per_tensor_default_8 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_8, 0.1227148175239563, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_8 = None\n",
      "    layer1_1_conv1 = getattr(self.layer1, \"1\").conv1(dequantize_per_tensor_default_8)\n",
      "    quantize_per_tensor_default_9 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_conv1, 0.16682936251163483, 89, 0, 127, torch.uint8);  layer1_1_conv1 = None\n",
      "    dequantize_per_tensor_default_9 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_9, 0.16682936251163483, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_9 = None\n",
      "    layer1_1_drop_block = getattr(self.layer1, \"1\").drop_block(dequantize_per_tensor_default_9);  dequantize_per_tensor_default_9 = None\n",
      "    quantize_per_tensor_default_10 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_drop_block, 0.16682936251163483, 89, 0, 127, torch.uint8);  layer1_1_drop_block = None\n",
      "    dequantize_per_tensor_default_10 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_10, 0.16682936251163483, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_10 = None\n",
      "    layer1_1_act1 = getattr(self.layer1, \"1\").act1(dequantize_per_tensor_default_10);  dequantize_per_tensor_default_10 = None\n",
      "    quantize_per_tensor_default_11 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_act1, 0.16682936251163483, 89, 0, 127, torch.uint8);  layer1_1_act1 = None\n",
      "    dequantize_per_tensor_default_11 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_11, 0.16682936251163483, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_11 = None\n",
      "    layer1_1_aa = getattr(self.layer1, \"1\").aa(dequantize_per_tensor_default_11);  dequantize_per_tensor_default_11 = None\n",
      "    quantize_per_tensor_default_12 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_aa, 0.16682936251163483, 89, 0, 127, torch.uint8);  layer1_1_aa = None\n",
      "    dequantize_per_tensor_default_12 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_12, 0.16682936251163483, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_12 = None\n",
      "    layer1_1_conv2 = getattr(self.layer1, \"1\").conv2(dequantize_per_tensor_default_12);  dequantize_per_tensor_default_12 = None\n",
      "    quantize_per_tensor_default_13 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_conv2, 0.46439093351364136, 89, 0, 127, torch.uint8);  layer1_1_conv2 = None\n",
      "    dequantize_per_tensor_default_13 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_13, 0.46439093351364136, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_13 = None\n",
      "    add_1 = dequantize_per_tensor_default_13 + dequantize_per_tensor_default_8;  dequantize_per_tensor_default_13 = dequantize_per_tensor_default_8 = None\n",
      "    layer1_1_act2 = getattr(self.layer1, \"1\").act2(add_1);  add_1 = None\n",
      "    quantize_per_tensor_default_14 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_act2, 0.16545970737934113, 0, 0, 127, torch.uint8);  layer1_1_act2 = None\n",
      "    dequantize_per_tensor_default_14 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_14, 0.16545970737934113, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_14 = None\n",
      "    layer2_0_conv1 = getattr(self.layer2, \"0\").conv1(dequantize_per_tensor_default_14)\n",
      "    quantize_per_tensor_default_15 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_conv1, 0.20702704787254333, 79, 0, 127, torch.uint8);  layer2_0_conv1 = None\n",
      "    dequantize_per_tensor_default_15 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_15, 0.20702704787254333, 79, 0, 127, torch.uint8);  quantize_per_tensor_default_15 = None\n",
      "    layer2_0_drop_block = getattr(self.layer2, \"0\").drop_block(dequantize_per_tensor_default_15);  dequantize_per_tensor_default_15 = None\n",
      "    quantize_per_tensor_default_16 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_drop_block, 0.20702704787254333, 79, 0, 127, torch.uint8);  layer2_0_drop_block = None\n",
      "    dequantize_per_tensor_default_16 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_16, 0.20702704787254333, 79, 0, 127, torch.uint8);  quantize_per_tensor_default_16 = None\n",
      "    layer2_0_act1 = getattr(self.layer2, \"0\").act1(dequantize_per_tensor_default_16);  dequantize_per_tensor_default_16 = None\n",
      "    quantize_per_tensor_default_17 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_act1, 0.20702704787254333, 79, 0, 127, torch.uint8);  layer2_0_act1 = None\n",
      "    dequantize_per_tensor_default_17 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_17, 0.20702704787254333, 79, 0, 127, torch.uint8);  quantize_per_tensor_default_17 = None\n",
      "    layer2_0_aa = getattr(self.layer2, \"0\").aa(dequantize_per_tensor_default_17);  dequantize_per_tensor_default_17 = None\n",
      "    quantize_per_tensor_default_18 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_aa, 0.20702704787254333, 79, 0, 127, torch.uint8);  layer2_0_aa = None\n",
      "    dequantize_per_tensor_default_18 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_18, 0.20702704787254333, 79, 0, 127, torch.uint8);  quantize_per_tensor_default_18 = None\n",
      "    layer2_0_conv2 = getattr(self.layer2, \"0\").conv2(dequantize_per_tensor_default_18);  dequantize_per_tensor_default_18 = None\n",
      "    quantize_per_tensor_default_19 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_conv2, 0.2782479226589203, 82, 0, 127, torch.uint8);  layer2_0_conv2 = None\n",
      "    dequantize_per_tensor_default_19 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_19, 0.2782479226589203, 82, 0, 127, torch.uint8);  quantize_per_tensor_default_19 = None\n",
      "    layer2_0_downsample_0 = getattr(getattr(self.layer2, \"0\").downsample, \"0\")(dequantize_per_tensor_default_14);  dequantize_per_tensor_default_14 = None\n",
      "    quantize_per_tensor_default_20 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_downsample_0, 0.20047928392887115, 82, 0, 127, torch.uint8);  layer2_0_downsample_0 = None\n",
      "    dequantize_per_tensor_default_20 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_20, 0.20047928392887115, 82, 0, 127, torch.uint8);  quantize_per_tensor_default_20 = None\n",
      "    add_2 = dequantize_per_tensor_default_19 + dequantize_per_tensor_default_20;  dequantize_per_tensor_default_19 = dequantize_per_tensor_default_20 = None\n",
      "    layer2_0_act2 = getattr(self.layer2, \"0\").act2(add_2);  add_2 = None\n",
      "    quantize_per_tensor_default_21 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_act2, 0.12949171662330627, 0, 0, 127, torch.uint8);  layer2_0_act2 = None\n",
      "    dequantize_per_tensor_default_21 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_21, 0.12949171662330627, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_21 = None\n",
      "    layer2_1_conv1 = getattr(self.layer2, \"1\").conv1(dequantize_per_tensor_default_21)\n",
      "    quantize_per_tensor_default_22 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_conv1, 0.23286855220794678, 88, 0, 127, torch.uint8);  layer2_1_conv1 = None\n",
      "    dequantize_per_tensor_default_22 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_22, 0.23286855220794678, 88, 0, 127, torch.uint8);  quantize_per_tensor_default_22 = None\n",
      "    layer2_1_drop_block = getattr(self.layer2, \"1\").drop_block(dequantize_per_tensor_default_22);  dequantize_per_tensor_default_22 = None\n",
      "    quantize_per_tensor_default_23 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_drop_block, 0.23286855220794678, 88, 0, 127, torch.uint8);  layer2_1_drop_block = None\n",
      "    dequantize_per_tensor_default_23 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_23, 0.23286855220794678, 88, 0, 127, torch.uint8);  quantize_per_tensor_default_23 = None\n",
      "    layer2_1_act1 = getattr(self.layer2, \"1\").act1(dequantize_per_tensor_default_23);  dequantize_per_tensor_default_23 = None\n",
      "    quantize_per_tensor_default_24 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_act1, 0.23286855220794678, 88, 0, 127, torch.uint8);  layer2_1_act1 = None\n",
      "    dequantize_per_tensor_default_24 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_24, 0.23286855220794678, 88, 0, 127, torch.uint8);  quantize_per_tensor_default_24 = None\n",
      "    layer2_1_aa = getattr(self.layer2, \"1\").aa(dequantize_per_tensor_default_24);  dequantize_per_tensor_default_24 = None\n",
      "    quantize_per_tensor_default_25 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_aa, 0.23286855220794678, 88, 0, 127, torch.uint8);  layer2_1_aa = None\n",
      "    dequantize_per_tensor_default_25 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_25, 0.23286855220794678, 88, 0, 127, torch.uint8);  quantize_per_tensor_default_25 = None\n",
      "    layer2_1_conv2 = getattr(self.layer2, \"1\").conv2(dequantize_per_tensor_default_25);  dequantize_per_tensor_default_25 = None\n",
      "    quantize_per_tensor_default_26 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_conv2, 0.3497721254825592, 75, 0, 127, torch.uint8);  layer2_1_conv2 = None\n",
      "    dequantize_per_tensor_default_26 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_26, 0.3497721254825592, 75, 0, 127, torch.uint8);  quantize_per_tensor_default_26 = None\n",
      "    add_3 = dequantize_per_tensor_default_26 + dequantize_per_tensor_default_21;  dequantize_per_tensor_default_26 = dequantize_per_tensor_default_21 = None\n",
      "    layer2_1_act2 = getattr(self.layer2, \"1\").act2(add_3);  add_3 = None\n",
      "    quantize_per_tensor_default_27 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_act2, 0.17213840782642365, 0, 0, 127, torch.uint8);  layer2_1_act2 = None\n",
      "    dequantize_per_tensor_default_27 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_27, 0.17213840782642365, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_27 = None\n",
      "    layer3_0_conv1 = getattr(self.layer3, \"0\").conv1(dequantize_per_tensor_default_27)\n",
      "    quantize_per_tensor_default_28 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_conv1, 0.5490153431892395, 59, 0, 127, torch.uint8);  layer3_0_conv1 = None\n",
      "    dequantize_per_tensor_default_28 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_28, 0.5490153431892395, 59, 0, 127, torch.uint8);  quantize_per_tensor_default_28 = None\n",
      "    layer3_0_drop_block = getattr(self.layer3, \"0\").drop_block(dequantize_per_tensor_default_28);  dequantize_per_tensor_default_28 = None\n",
      "    quantize_per_tensor_default_29 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_drop_block, 0.5490153431892395, 59, 0, 127, torch.uint8);  layer3_0_drop_block = None\n",
      "    dequantize_per_tensor_default_29 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_29, 0.5490153431892395, 59, 0, 127, torch.uint8);  quantize_per_tensor_default_29 = None\n",
      "    layer3_0_act1 = getattr(self.layer3, \"0\").act1(dequantize_per_tensor_default_29);  dequantize_per_tensor_default_29 = None\n",
      "    quantize_per_tensor_default_30 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_act1, 0.5490153431892395, 59, 0, 127, torch.uint8);  layer3_0_act1 = None\n",
      "    dequantize_per_tensor_default_30 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_30, 0.5490153431892395, 59, 0, 127, torch.uint8);  quantize_per_tensor_default_30 = None\n",
      "    layer3_0_aa = getattr(self.layer3, \"0\").aa(dequantize_per_tensor_default_30);  dequantize_per_tensor_default_30 = None\n",
      "    quantize_per_tensor_default_31 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_aa, 0.5490153431892395, 59, 0, 127, torch.uint8);  layer3_0_aa = None\n",
      "    dequantize_per_tensor_default_31 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_31, 0.5490153431892395, 59, 0, 127, torch.uint8);  quantize_per_tensor_default_31 = None\n",
      "    layer3_0_conv2 = getattr(self.layer3, \"0\").conv2(dequantize_per_tensor_default_31);  dequantize_per_tensor_default_31 = None\n",
      "    quantize_per_tensor_default_32 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_conv2, 0.4171593189239502, 76, 0, 127, torch.uint8);  layer3_0_conv2 = None\n",
      "    dequantize_per_tensor_default_32 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_32, 0.4171593189239502, 76, 0, 127, torch.uint8);  quantize_per_tensor_default_32 = None\n",
      "    layer3_0_downsample_0 = getattr(getattr(self.layer3, \"0\").downsample, \"0\")(dequantize_per_tensor_default_27);  dequantize_per_tensor_default_27 = None\n",
      "    quantize_per_tensor_default_33 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_downsample_0, 0.17532892525196075, 79, 0, 127, torch.uint8);  layer3_0_downsample_0 = None\n",
      "    dequantize_per_tensor_default_33 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 0.17532892525196075, 79, 0, 127, torch.uint8);  quantize_per_tensor_default_33 = None\n",
      "    add_4 = dequantize_per_tensor_default_32 + dequantize_per_tensor_default_33;  dequantize_per_tensor_default_32 = dequantize_per_tensor_default_33 = None\n",
      "    layer3_0_act2 = getattr(self.layer3, \"0\").act2(add_4);  add_4 = None\n",
      "    quantize_per_tensor_default_34 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_act2, 0.20618410408496857, 0, 0, 127, torch.uint8);  layer3_0_act2 = None\n",
      "    dequantize_per_tensor_default_34 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_34, 0.20618410408496857, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_34 = None\n",
      "    layer3_1_conv1 = getattr(self.layer3, \"1\").conv1(dequantize_per_tensor_default_34)\n",
      "    quantize_per_tensor_default_35 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_conv1, 0.2892705202102661, 76, 0, 127, torch.uint8);  layer3_1_conv1 = None\n",
      "    dequantize_per_tensor_default_35 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_35, 0.2892705202102661, 76, 0, 127, torch.uint8);  quantize_per_tensor_default_35 = None\n",
      "    layer3_1_drop_block = getattr(self.layer3, \"1\").drop_block(dequantize_per_tensor_default_35);  dequantize_per_tensor_default_35 = None\n",
      "    quantize_per_tensor_default_36 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_drop_block, 0.2892705202102661, 76, 0, 127, torch.uint8);  layer3_1_drop_block = None\n",
      "    dequantize_per_tensor_default_36 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_36, 0.2892705202102661, 76, 0, 127, torch.uint8);  quantize_per_tensor_default_36 = None\n",
      "    layer3_1_act1 = getattr(self.layer3, \"1\").act1(dequantize_per_tensor_default_36);  dequantize_per_tensor_default_36 = None\n",
      "    quantize_per_tensor_default_37 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_act1, 0.2892705202102661, 76, 0, 127, torch.uint8);  layer3_1_act1 = None\n",
      "    dequantize_per_tensor_default_37 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_37, 0.2892705202102661, 76, 0, 127, torch.uint8);  quantize_per_tensor_default_37 = None\n",
      "    layer3_1_aa = getattr(self.layer3, \"1\").aa(dequantize_per_tensor_default_37);  dequantize_per_tensor_default_37 = None\n",
      "    quantize_per_tensor_default_38 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_aa, 0.2892705202102661, 76, 0, 127, torch.uint8);  layer3_1_aa = None\n",
      "    dequantize_per_tensor_default_38 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_38, 0.2892705202102661, 76, 0, 127, torch.uint8);  quantize_per_tensor_default_38 = None\n",
      "    layer3_1_conv2 = getattr(self.layer3, \"1\").conv2(dequantize_per_tensor_default_38);  dequantize_per_tensor_default_38 = None\n",
      "    quantize_per_tensor_default_39 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_conv2, 0.42308375239372253, 80, 0, 127, torch.uint8);  layer3_1_conv2 = None\n",
      "    dequantize_per_tensor_default_39 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_39, 0.42308375239372253, 80, 0, 127, torch.uint8);  quantize_per_tensor_default_39 = None\n",
      "    add_5 = dequantize_per_tensor_default_39 + dequantize_per_tensor_default_34;  dequantize_per_tensor_default_39 = dequantize_per_tensor_default_34 = None\n",
      "    layer3_1_act2 = getattr(self.layer3, \"1\").act2(add_5);  add_5 = None\n",
      "    quantize_per_tensor_default_40 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_act2, 0.24419252574443817, 0, 0, 127, torch.uint8);  layer3_1_act2 = None\n",
      "    dequantize_per_tensor_default_40 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_40, 0.24419252574443817, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_40 = None\n",
      "    layer4_0_conv1 = getattr(self.layer4, \"0\").conv1(dequantize_per_tensor_default_40)\n",
      "    quantize_per_tensor_default_41 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_conv1, 0.2719169557094574, 69, 0, 127, torch.uint8);  layer4_0_conv1 = None\n",
      "    dequantize_per_tensor_default_41 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_41, 0.2719169557094574, 69, 0, 127, torch.uint8);  quantize_per_tensor_default_41 = None\n",
      "    layer4_0_drop_block = getattr(self.layer4, \"0\").drop_block(dequantize_per_tensor_default_41);  dequantize_per_tensor_default_41 = None\n",
      "    quantize_per_tensor_default_42 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_drop_block, 0.2719169557094574, 69, 0, 127, torch.uint8);  layer4_0_drop_block = None\n",
      "    dequantize_per_tensor_default_42 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_42, 0.2719169557094574, 69, 0, 127, torch.uint8);  quantize_per_tensor_default_42 = None\n",
      "    layer4_0_act1 = getattr(self.layer4, \"0\").act1(dequantize_per_tensor_default_42);  dequantize_per_tensor_default_42 = None\n",
      "    quantize_per_tensor_default_43 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_act1, 0.2719169557094574, 69, 0, 127, torch.uint8);  layer4_0_act1 = None\n",
      "    dequantize_per_tensor_default_43 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_43, 0.2719169557094574, 69, 0, 127, torch.uint8);  quantize_per_tensor_default_43 = None\n",
      "    layer4_0_aa = getattr(self.layer4, \"0\").aa(dequantize_per_tensor_default_43);  dequantize_per_tensor_default_43 = None\n",
      "    quantize_per_tensor_default_44 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_aa, 0.2719169557094574, 69, 0, 127, torch.uint8);  layer4_0_aa = None\n",
      "    dequantize_per_tensor_default_44 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_44, 0.2719169557094574, 69, 0, 127, torch.uint8);  quantize_per_tensor_default_44 = None\n",
      "    layer4_0_conv2 = getattr(self.layer4, \"0\").conv2(dequantize_per_tensor_default_44);  dequantize_per_tensor_default_44 = None\n",
      "    quantize_per_tensor_default_45 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_conv2, 0.2542303204536438, 75, 0, 127, torch.uint8);  layer4_0_conv2 = None\n",
      "    dequantize_per_tensor_default_45 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_45, 0.2542303204536438, 75, 0, 127, torch.uint8);  quantize_per_tensor_default_45 = None\n",
      "    layer4_0_downsample_0 = getattr(getattr(self.layer4, \"0\").downsample, \"0\")(dequantize_per_tensor_default_40);  dequantize_per_tensor_default_40 = None\n",
      "    quantize_per_tensor_default_46 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_downsample_0, 0.17691001296043396, 68, 0, 127, torch.uint8);  layer4_0_downsample_0 = None\n",
      "    dequantize_per_tensor_default_46 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_46, 0.17691001296043396, 68, 0, 127, torch.uint8);  quantize_per_tensor_default_46 = None\n",
      "    add_6 = dequantize_per_tensor_default_45 + dequantize_per_tensor_default_46;  dequantize_per_tensor_default_45 = dequantize_per_tensor_default_46 = None\n",
      "    layer4_0_act2 = getattr(self.layer4, \"0\").act2(add_6);  add_6 = None\n",
      "    quantize_per_tensor_default_47 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_act2, 0.1456831991672516, 0, 0, 127, torch.uint8);  layer4_0_act2 = None\n",
      "    dequantize_per_tensor_default_47 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_47, 0.1456831991672516, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_47 = None\n",
      "    layer4_1_conv1 = getattr(self.layer4, \"1\").conv1(dequantize_per_tensor_default_47)\n",
      "    quantize_per_tensor_default_48 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_conv1, 0.25498130917549133, 90, 0, 127, torch.uint8);  layer4_1_conv1 = None\n",
      "    dequantize_per_tensor_default_48 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_48, 0.25498130917549133, 90, 0, 127, torch.uint8);  quantize_per_tensor_default_48 = None\n",
      "    layer4_1_drop_block = getattr(self.layer4, \"1\").drop_block(dequantize_per_tensor_default_48);  dequantize_per_tensor_default_48 = None\n",
      "    quantize_per_tensor_default_49 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_drop_block, 0.25498130917549133, 90, 0, 127, torch.uint8);  layer4_1_drop_block = None\n",
      "    dequantize_per_tensor_default_49 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_49, 0.25498130917549133, 90, 0, 127, torch.uint8);  quantize_per_tensor_default_49 = None\n",
      "    layer4_1_act1 = getattr(self.layer4, \"1\").act1(dequantize_per_tensor_default_49);  dequantize_per_tensor_default_49 = None\n",
      "    quantize_per_tensor_default_50 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_act1, 0.25498130917549133, 90, 0, 127, torch.uint8);  layer4_1_act1 = None\n",
      "    dequantize_per_tensor_default_50 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_50, 0.25498130917549133, 90, 0, 127, torch.uint8);  quantize_per_tensor_default_50 = None\n",
      "    layer4_1_aa = getattr(self.layer4, \"1\").aa(dequantize_per_tensor_default_50);  dequantize_per_tensor_default_50 = None\n",
      "    quantize_per_tensor_default_51 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_aa, 0.25498130917549133, 90, 0, 127, torch.uint8);  layer4_1_aa = None\n",
      "    dequantize_per_tensor_default_51 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_51, 0.25498130917549133, 90, 0, 127, torch.uint8);  quantize_per_tensor_default_51 = None\n",
      "    layer4_1_conv2 = getattr(self.layer4, \"1\").conv2(dequantize_per_tensor_default_51);  dequantize_per_tensor_default_51 = None\n",
      "    quantize_per_tensor_default_52 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_conv2, 0.34592631459236145, 89, 0, 127, torch.uint8);  layer4_1_conv2 = None\n",
      "    dequantize_per_tensor_default_52 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_52, 0.34592631459236145, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_52 = None\n",
      "    add_7 = dequantize_per_tensor_default_52 + dequantize_per_tensor_default_47;  dequantize_per_tensor_default_52 = dequantize_per_tensor_default_47 = None\n",
      "    layer4_1_act2 = getattr(self.layer4, \"1\").act2(add_7);  add_7 = None\n",
      "    quantize_per_tensor_default_53 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_act2, 0.15677042305469513, 0, 0, 127, torch.uint8);  layer4_1_act2 = None\n",
      "    dequantize_per_tensor_default_53 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_53, 0.15677042305469513, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_53 = None\n",
      "    global_pool_pool = self.global_pool.pool(dequantize_per_tensor_default_53);  dequantize_per_tensor_default_53 = None\n",
      "    quantize_per_tensor_default_54 = torch.ops.quantized_decomposed.quantize_per_tensor.default(global_pool_pool, 0.15677042305469513, 0, 0, 127, torch.uint8);  global_pool_pool = None\n",
      "    dequantize_per_tensor_default_54 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_54, 0.15677042305469513, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_54 = None\n",
      "    global_pool_flatten = self.global_pool.flatten(dequantize_per_tensor_default_54);  dequantize_per_tensor_default_54 = None\n",
      "    quantize_per_tensor_default_55 = torch.ops.quantized_decomposed.quantize_per_tensor.default(global_pool_flatten, 0.02608378976583481, 0, 0, 127, torch.uint8);  global_pool_flatten = None\n",
      "    dequantize_per_tensor_default_55 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_55, 0.02608378976583481, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_55 = None\n",
      "    fc = self.fc(dequantize_per_tensor_default_55);  dequantize_per_tensor_default_55 = None\n",
      "    quantize_per_tensor_default_56 = torch.ops.quantized_decomposed.quantize_per_tensor.default(fc, 0.2907339632511139, 82, 0, 127, torch.uint8);  fc = None\n",
      "    dequantize_per_tensor_default_56 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_56, 0.2907339632511139, 82, 0, 127, torch.uint8);  quantize_per_tensor_default_56 = None\n",
      "    return dequantize_per_tensor_default_56\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "# quantized_model = _convert_fx(prepared_model,is_reference=False,)\n",
    "quantized_model = _convert_fx(prepared_model,is_reference=False)\n",
    "# quantized_model = convert_to_reference_fx(prepared_model)\n",
    "print(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2da4580e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T10:09:29.092219Z",
     "start_time": "2023-06-02T10:09:27.931918Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/wrq/quant_learning/pytorch_quant_fx.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#print_size_of_model(quantized_model)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m top1, top5 \u001b[39m=\u001b[39m evaluate(quantized_model, criterion, data_loader_test)\n",
      "\u001b[1;32m/home/wrq/quant_learning/pytorch_quant_fx.ipynb Cell 11\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, criterion, data_loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m cnt \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mfor\u001b[39;00m image, target \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m         output \u001b[39m=\u001b[39m model(image)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m         loss \u001b[39m=\u001b[39m criterion(output, target)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torchvision/datasets/folder.py:229\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[39m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m path, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples[index]\n\u001b[0;32m--> 229\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader(path)\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torchvision/datasets/folder.py:268\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[39mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    267\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mreturn\u001b[39;00m pil_loader(path)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torchvision/datasets/folder.py:248\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    247\u001b[0m     img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(f)\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mconvert(\u001b[39m\"\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/PIL/Image.py:921\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\n\u001b[1;32m    874\u001b[0m     \u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dither\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39mPalette\u001b[39m.\u001b[39mWEB, colors\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m\n\u001b[1;32m    875\u001b[0m ):\n\u001b[1;32m    876\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 921\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    923\u001b[0m     has_transparency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    924\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    925\u001b[0m         \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/PIL/ImageFile.py:209\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_prepare()\n\u001b[1;32m    210\u001b[0m err_code \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m3\u001b[39m  \u001b[39m# initialize to unknown error\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmap:\n\u001b[1;32m    212\u001b[0m     \u001b[39m# sort tiles in file order\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/PIL/ImageFile.py:286\u001b[0m, in \u001b[0;36mImageFile.load_prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_prepare\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    284\u001b[0m     \u001b[39m# create image memory if necessary\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim\u001b[39m.\u001b[39mmode \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim\u001b[39m.\u001b[39msize \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize:\n\u001b[0;32m--> 286\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mcore\u001b[39m.\u001b[39;49mnew(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize)\n\u001b[1;32m    287\u001b[0m     \u001b[39m# create palette (optional)\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#print_size_of_model(quantized_model)\n",
    "top1, top5 = evaluate(quantized_model, criterion, data_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea5151d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (conv1): ConvReLU2d(\n",
      "    (0): QuantizedConv2d(Reference)(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Module(\n",
      "    (0): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Module(\n",
      "    (0): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (downsample): Module(\n",
      "        (0): QuantizedConv2d(Reference)(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "      )\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Module(\n",
      "    (0): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (downsample): Module(\n",
      "        (0): QuantizedConv2d(Reference)(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "      )\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Module(\n",
      "    (0): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (downsample): Module(\n",
      "        (0): QuantizedConv2d(Reference)(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "      )\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Module(\n",
      "      (conv1): QuantizedConv2d(Reference)(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): QuantizedConv2d(Reference)(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): Module(\n",
      "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (fc): QuantizedLinear(Reference)(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.037445519119501114, 57, 0, 127, torch.uint8);  x = None\n",
      "    dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.037445519119501114, 57, 0, 127, torch.uint8);  quantize_per_tensor_default = None\n",
      "    conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None\n",
      "    quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.12883716821670532, 0, 0, 127, torch.uint8);  conv1 = None\n",
      "    dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.12883716821670532, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_1 = None\n",
      "    maxpool = self.maxpool(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None\n",
      "    quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(maxpool, 0.12883716821670532, 0, 0, 127, torch.uint8);  maxpool = None\n",
      "    dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.12883716821670532, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_2 = None\n",
      "    layer1_0_conv1 = getattr(self.layer1, \"0\").conv1(dequantize_per_tensor_default_2)\n",
      "    quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_conv1, 0.13203494250774384, 86, 0, 127, torch.uint8);  layer1_0_conv1 = None\n",
      "    dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.13203494250774384, 86, 0, 127, torch.uint8);  quantize_per_tensor_default_3 = None\n",
      "    layer1_0_drop_block = getattr(self.layer1, \"0\").drop_block(dequantize_per_tensor_default_3);  dequantize_per_tensor_default_3 = None\n",
      "    quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_drop_block, 0.13203494250774384, 86, 0, 127, torch.uint8);  layer1_0_drop_block = None\n",
      "    dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.13203494250774384, 86, 0, 127, torch.uint8);  quantize_per_tensor_default_4 = None\n",
      "    layer1_0_act1 = getattr(self.layer1, \"0\").act1(dequantize_per_tensor_default_4);  dequantize_per_tensor_default_4 = None\n",
      "    quantize_per_tensor_default_5 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_act1, 0.13203494250774384, 86, 0, 127, torch.uint8);  layer1_0_act1 = None\n",
      "    dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_5, 0.13203494250774384, 86, 0, 127, torch.uint8);  quantize_per_tensor_default_5 = None\n",
      "    layer1_0_aa = getattr(self.layer1, \"0\").aa(dequantize_per_tensor_default_5);  dequantize_per_tensor_default_5 = None\n",
      "    quantize_per_tensor_default_6 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_aa, 0.13203494250774384, 86, 0, 127, torch.uint8);  layer1_0_aa = None\n",
      "    dequantize_per_tensor_default_6 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_6, 0.13203494250774384, 86, 0, 127, torch.uint8);  quantize_per_tensor_default_6 = None\n",
      "    layer1_0_conv2 = getattr(self.layer1, \"0\").conv2(dequantize_per_tensor_default_6);  dequantize_per_tensor_default_6 = None\n",
      "    quantize_per_tensor_default_7 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_conv2, 0.2708899974822998, 90, 0, 127, torch.uint8);  layer1_0_conv2 = None\n",
      "    dequantize_per_tensor_default_7 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_7, 0.2708899974822998, 90, 0, 127, torch.uint8);  quantize_per_tensor_default_7 = None\n",
      "    add = dequantize_per_tensor_default_7 + dequantize_per_tensor_default_2;  dequantize_per_tensor_default_7 = dequantize_per_tensor_default_2 = None\n",
      "    layer1_0_act2 = getattr(self.layer1, \"0\").act2(add);  add = None\n",
      "    quantize_per_tensor_default_8 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_0_act2, 0.1227148175239563, 0, 0, 127, torch.uint8);  layer1_0_act2 = None\n",
      "    dequantize_per_tensor_default_8 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_8, 0.1227148175239563, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_8 = None\n",
      "    layer1_1_conv1 = getattr(self.layer1, \"1\").conv1(dequantize_per_tensor_default_8)\n",
      "    quantize_per_tensor_default_9 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_conv1, 0.16682936251163483, 89, 0, 127, torch.uint8);  layer1_1_conv1 = None\n",
      "    dequantize_per_tensor_default_9 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_9, 0.16682936251163483, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_9 = None\n",
      "    layer1_1_drop_block = getattr(self.layer1, \"1\").drop_block(dequantize_per_tensor_default_9);  dequantize_per_tensor_default_9 = None\n",
      "    quantize_per_tensor_default_10 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_drop_block, 0.16682936251163483, 89, 0, 127, torch.uint8);  layer1_1_drop_block = None\n",
      "    dequantize_per_tensor_default_10 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_10, 0.16682936251163483, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_10 = None\n",
      "    layer1_1_act1 = getattr(self.layer1, \"1\").act1(dequantize_per_tensor_default_10);  dequantize_per_tensor_default_10 = None\n",
      "    quantize_per_tensor_default_11 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_act1, 0.16682936251163483, 89, 0, 127, torch.uint8);  layer1_1_act1 = None\n",
      "    dequantize_per_tensor_default_11 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_11, 0.16682936251163483, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_11 = None\n",
      "    layer1_1_aa = getattr(self.layer1, \"1\").aa(dequantize_per_tensor_default_11);  dequantize_per_tensor_default_11 = None\n",
      "    quantize_per_tensor_default_12 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_aa, 0.16682936251163483, 89, 0, 127, torch.uint8);  layer1_1_aa = None\n",
      "    dequantize_per_tensor_default_12 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_12, 0.16682936251163483, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_12 = None\n",
      "    layer1_1_conv2 = getattr(self.layer1, \"1\").conv2(dequantize_per_tensor_default_12);  dequantize_per_tensor_default_12 = None\n",
      "    quantize_per_tensor_default_13 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_conv2, 0.46439093351364136, 89, 0, 127, torch.uint8);  layer1_1_conv2 = None\n",
      "    dequantize_per_tensor_default_13 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_13, 0.46439093351364136, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_13 = None\n",
      "    add_1 = dequantize_per_tensor_default_13 + dequantize_per_tensor_default_8;  dequantize_per_tensor_default_13 = dequantize_per_tensor_default_8 = None\n",
      "    layer1_1_act2 = getattr(self.layer1, \"1\").act2(add_1);  add_1 = None\n",
      "    quantize_per_tensor_default_14 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer1_1_act2, 0.16545970737934113, 0, 0, 127, torch.uint8);  layer1_1_act2 = None\n",
      "    dequantize_per_tensor_default_14 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_14, 0.16545970737934113, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_14 = None\n",
      "    layer2_0_conv1 = getattr(self.layer2, \"0\").conv1(dequantize_per_tensor_default_14)\n",
      "    quantize_per_tensor_default_15 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_conv1, 0.20702704787254333, 79, 0, 127, torch.uint8);  layer2_0_conv1 = None\n",
      "    dequantize_per_tensor_default_15 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_15, 0.20702704787254333, 79, 0, 127, torch.uint8);  quantize_per_tensor_default_15 = None\n",
      "    layer2_0_drop_block = getattr(self.layer2, \"0\").drop_block(dequantize_per_tensor_default_15);  dequantize_per_tensor_default_15 = None\n",
      "    quantize_per_tensor_default_16 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_drop_block, 0.20702704787254333, 79, 0, 127, torch.uint8);  layer2_0_drop_block = None\n",
      "    dequantize_per_tensor_default_16 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_16, 0.20702704787254333, 79, 0, 127, torch.uint8);  quantize_per_tensor_default_16 = None\n",
      "    layer2_0_act1 = getattr(self.layer2, \"0\").act1(dequantize_per_tensor_default_16);  dequantize_per_tensor_default_16 = None\n",
      "    quantize_per_tensor_default_17 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_act1, 0.20702704787254333, 79, 0, 127, torch.uint8);  layer2_0_act1 = None\n",
      "    dequantize_per_tensor_default_17 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_17, 0.20702704787254333, 79, 0, 127, torch.uint8);  quantize_per_tensor_default_17 = None\n",
      "    layer2_0_aa = getattr(self.layer2, \"0\").aa(dequantize_per_tensor_default_17);  dequantize_per_tensor_default_17 = None\n",
      "    quantize_per_tensor_default_18 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_aa, 0.20702704787254333, 79, 0, 127, torch.uint8);  layer2_0_aa = None\n",
      "    dequantize_per_tensor_default_18 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_18, 0.20702704787254333, 79, 0, 127, torch.uint8);  quantize_per_tensor_default_18 = None\n",
      "    layer2_0_conv2 = getattr(self.layer2, \"0\").conv2(dequantize_per_tensor_default_18);  dequantize_per_tensor_default_18 = None\n",
      "    quantize_per_tensor_default_19 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_conv2, 0.2782479226589203, 82, 0, 127, torch.uint8);  layer2_0_conv2 = None\n",
      "    dequantize_per_tensor_default_19 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_19, 0.2782479226589203, 82, 0, 127, torch.uint8);  quantize_per_tensor_default_19 = None\n",
      "    layer2_0_downsample_0 = getattr(getattr(self.layer2, \"0\").downsample, \"0\")(dequantize_per_tensor_default_14);  dequantize_per_tensor_default_14 = None\n",
      "    quantize_per_tensor_default_20 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_downsample_0, 0.20047928392887115, 82, 0, 127, torch.uint8);  layer2_0_downsample_0 = None\n",
      "    dequantize_per_tensor_default_20 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_20, 0.20047928392887115, 82, 0, 127, torch.uint8);  quantize_per_tensor_default_20 = None\n",
      "    add_2 = dequantize_per_tensor_default_19 + dequantize_per_tensor_default_20;  dequantize_per_tensor_default_19 = dequantize_per_tensor_default_20 = None\n",
      "    layer2_0_act2 = getattr(self.layer2, \"0\").act2(add_2);  add_2 = None\n",
      "    quantize_per_tensor_default_21 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_0_act2, 0.12949171662330627, 0, 0, 127, torch.uint8);  layer2_0_act2 = None\n",
      "    dequantize_per_tensor_default_21 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_21, 0.12949171662330627, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_21 = None\n",
      "    layer2_1_conv1 = getattr(self.layer2, \"1\").conv1(dequantize_per_tensor_default_21)\n",
      "    quantize_per_tensor_default_22 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_conv1, 0.23286855220794678, 88, 0, 127, torch.uint8);  layer2_1_conv1 = None\n",
      "    dequantize_per_tensor_default_22 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_22, 0.23286855220794678, 88, 0, 127, torch.uint8);  quantize_per_tensor_default_22 = None\n",
      "    layer2_1_drop_block = getattr(self.layer2, \"1\").drop_block(dequantize_per_tensor_default_22);  dequantize_per_tensor_default_22 = None\n",
      "    quantize_per_tensor_default_23 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_drop_block, 0.23286855220794678, 88, 0, 127, torch.uint8);  layer2_1_drop_block = None\n",
      "    dequantize_per_tensor_default_23 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_23, 0.23286855220794678, 88, 0, 127, torch.uint8);  quantize_per_tensor_default_23 = None\n",
      "    layer2_1_act1 = getattr(self.layer2, \"1\").act1(dequantize_per_tensor_default_23);  dequantize_per_tensor_default_23 = None\n",
      "    quantize_per_tensor_default_24 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_act1, 0.23286855220794678, 88, 0, 127, torch.uint8);  layer2_1_act1 = None\n",
      "    dequantize_per_tensor_default_24 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_24, 0.23286855220794678, 88, 0, 127, torch.uint8);  quantize_per_tensor_default_24 = None\n",
      "    layer2_1_aa = getattr(self.layer2, \"1\").aa(dequantize_per_tensor_default_24);  dequantize_per_tensor_default_24 = None\n",
      "    quantize_per_tensor_default_25 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_aa, 0.23286855220794678, 88, 0, 127, torch.uint8);  layer2_1_aa = None\n",
      "    dequantize_per_tensor_default_25 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_25, 0.23286855220794678, 88, 0, 127, torch.uint8);  quantize_per_tensor_default_25 = None\n",
      "    layer2_1_conv2 = getattr(self.layer2, \"1\").conv2(dequantize_per_tensor_default_25);  dequantize_per_tensor_default_25 = None\n",
      "    quantize_per_tensor_default_26 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_conv2, 0.3497721254825592, 75, 0, 127, torch.uint8);  layer2_1_conv2 = None\n",
      "    dequantize_per_tensor_default_26 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_26, 0.3497721254825592, 75, 0, 127, torch.uint8);  quantize_per_tensor_default_26 = None\n",
      "    add_3 = dequantize_per_tensor_default_26 + dequantize_per_tensor_default_21;  dequantize_per_tensor_default_26 = dequantize_per_tensor_default_21 = None\n",
      "    layer2_1_act2 = getattr(self.layer2, \"1\").act2(add_3);  add_3 = None\n",
      "    quantize_per_tensor_default_27 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer2_1_act2, 0.17213840782642365, 0, 0, 127, torch.uint8);  layer2_1_act2 = None\n",
      "    dequantize_per_tensor_default_27 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_27, 0.17213840782642365, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_27 = None\n",
      "    layer3_0_conv1 = getattr(self.layer3, \"0\").conv1(dequantize_per_tensor_default_27)\n",
      "    quantize_per_tensor_default_28 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_conv1, 0.5490153431892395, 59, 0, 127, torch.uint8);  layer3_0_conv1 = None\n",
      "    dequantize_per_tensor_default_28 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_28, 0.5490153431892395, 59, 0, 127, torch.uint8);  quantize_per_tensor_default_28 = None\n",
      "    layer3_0_drop_block = getattr(self.layer3, \"0\").drop_block(dequantize_per_tensor_default_28);  dequantize_per_tensor_default_28 = None\n",
      "    quantize_per_tensor_default_29 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_drop_block, 0.5490153431892395, 59, 0, 127, torch.uint8);  layer3_0_drop_block = None\n",
      "    dequantize_per_tensor_default_29 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_29, 0.5490153431892395, 59, 0, 127, torch.uint8);  quantize_per_tensor_default_29 = None\n",
      "    layer3_0_act1 = getattr(self.layer3, \"0\").act1(dequantize_per_tensor_default_29);  dequantize_per_tensor_default_29 = None\n",
      "    quantize_per_tensor_default_30 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_act1, 0.5490153431892395, 59, 0, 127, torch.uint8);  layer3_0_act1 = None\n",
      "    dequantize_per_tensor_default_30 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_30, 0.5490153431892395, 59, 0, 127, torch.uint8);  quantize_per_tensor_default_30 = None\n",
      "    layer3_0_aa = getattr(self.layer3, \"0\").aa(dequantize_per_tensor_default_30);  dequantize_per_tensor_default_30 = None\n",
      "    quantize_per_tensor_default_31 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_aa, 0.5490153431892395, 59, 0, 127, torch.uint8);  layer3_0_aa = None\n",
      "    dequantize_per_tensor_default_31 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_31, 0.5490153431892395, 59, 0, 127, torch.uint8);  quantize_per_tensor_default_31 = None\n",
      "    layer3_0_conv2 = getattr(self.layer3, \"0\").conv2(dequantize_per_tensor_default_31);  dequantize_per_tensor_default_31 = None\n",
      "    quantize_per_tensor_default_32 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_conv2, 0.4171593189239502, 76, 0, 127, torch.uint8);  layer3_0_conv2 = None\n",
      "    dequantize_per_tensor_default_32 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_32, 0.4171593189239502, 76, 0, 127, torch.uint8);  quantize_per_tensor_default_32 = None\n",
      "    layer3_0_downsample_0 = getattr(getattr(self.layer3, \"0\").downsample, \"0\")(dequantize_per_tensor_default_27);  dequantize_per_tensor_default_27 = None\n",
      "    quantize_per_tensor_default_33 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_downsample_0, 0.17532892525196075, 79, 0, 127, torch.uint8);  layer3_0_downsample_0 = None\n",
      "    dequantize_per_tensor_default_33 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 0.17532892525196075, 79, 0, 127, torch.uint8);  quantize_per_tensor_default_33 = None\n",
      "    add_4 = dequantize_per_tensor_default_32 + dequantize_per_tensor_default_33;  dequantize_per_tensor_default_32 = dequantize_per_tensor_default_33 = None\n",
      "    layer3_0_act2 = getattr(self.layer3, \"0\").act2(add_4);  add_4 = None\n",
      "    quantize_per_tensor_default_34 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_0_act2, 0.20618410408496857, 0, 0, 127, torch.uint8);  layer3_0_act2 = None\n",
      "    dequantize_per_tensor_default_34 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_34, 0.20618410408496857, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_34 = None\n",
      "    layer3_1_conv1 = getattr(self.layer3, \"1\").conv1(dequantize_per_tensor_default_34)\n",
      "    quantize_per_tensor_default_35 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_conv1, 0.2892705202102661, 76, 0, 127, torch.uint8);  layer3_1_conv1 = None\n",
      "    dequantize_per_tensor_default_35 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_35, 0.2892705202102661, 76, 0, 127, torch.uint8);  quantize_per_tensor_default_35 = None\n",
      "    layer3_1_drop_block = getattr(self.layer3, \"1\").drop_block(dequantize_per_tensor_default_35);  dequantize_per_tensor_default_35 = None\n",
      "    quantize_per_tensor_default_36 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_drop_block, 0.2892705202102661, 76, 0, 127, torch.uint8);  layer3_1_drop_block = None\n",
      "    dequantize_per_tensor_default_36 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_36, 0.2892705202102661, 76, 0, 127, torch.uint8);  quantize_per_tensor_default_36 = None\n",
      "    layer3_1_act1 = getattr(self.layer3, \"1\").act1(dequantize_per_tensor_default_36);  dequantize_per_tensor_default_36 = None\n",
      "    quantize_per_tensor_default_37 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_act1, 0.2892705202102661, 76, 0, 127, torch.uint8);  layer3_1_act1 = None\n",
      "    dequantize_per_tensor_default_37 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_37, 0.2892705202102661, 76, 0, 127, torch.uint8);  quantize_per_tensor_default_37 = None\n",
      "    layer3_1_aa = getattr(self.layer3, \"1\").aa(dequantize_per_tensor_default_37);  dequantize_per_tensor_default_37 = None\n",
      "    quantize_per_tensor_default_38 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_aa, 0.2892705202102661, 76, 0, 127, torch.uint8);  layer3_1_aa = None\n",
      "    dequantize_per_tensor_default_38 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_38, 0.2892705202102661, 76, 0, 127, torch.uint8);  quantize_per_tensor_default_38 = None\n",
      "    layer3_1_conv2 = getattr(self.layer3, \"1\").conv2(dequantize_per_tensor_default_38);  dequantize_per_tensor_default_38 = None\n",
      "    quantize_per_tensor_default_39 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_conv2, 0.42308375239372253, 80, 0, 127, torch.uint8);  layer3_1_conv2 = None\n",
      "    dequantize_per_tensor_default_39 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_39, 0.42308375239372253, 80, 0, 127, torch.uint8);  quantize_per_tensor_default_39 = None\n",
      "    add_5 = dequantize_per_tensor_default_39 + dequantize_per_tensor_default_34;  dequantize_per_tensor_default_39 = dequantize_per_tensor_default_34 = None\n",
      "    layer3_1_act2 = getattr(self.layer3, \"1\").act2(add_5);  add_5 = None\n",
      "    quantize_per_tensor_default_40 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer3_1_act2, 0.24419252574443817, 0, 0, 127, torch.uint8);  layer3_1_act2 = None\n",
      "    dequantize_per_tensor_default_40 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_40, 0.24419252574443817, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_40 = None\n",
      "    layer4_0_conv1 = getattr(self.layer4, \"0\").conv1(dequantize_per_tensor_default_40)\n",
      "    quantize_per_tensor_default_41 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_conv1, 0.2719169557094574, 69, 0, 127, torch.uint8);  layer4_0_conv1 = None\n",
      "    dequantize_per_tensor_default_41 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_41, 0.2719169557094574, 69, 0, 127, torch.uint8);  quantize_per_tensor_default_41 = None\n",
      "    layer4_0_drop_block = getattr(self.layer4, \"0\").drop_block(dequantize_per_tensor_default_41);  dequantize_per_tensor_default_41 = None\n",
      "    quantize_per_tensor_default_42 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_drop_block, 0.2719169557094574, 69, 0, 127, torch.uint8);  layer4_0_drop_block = None\n",
      "    dequantize_per_tensor_default_42 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_42, 0.2719169557094574, 69, 0, 127, torch.uint8);  quantize_per_tensor_default_42 = None\n",
      "    layer4_0_act1 = getattr(self.layer4, \"0\").act1(dequantize_per_tensor_default_42);  dequantize_per_tensor_default_42 = None\n",
      "    quantize_per_tensor_default_43 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_act1, 0.2719169557094574, 69, 0, 127, torch.uint8);  layer4_0_act1 = None\n",
      "    dequantize_per_tensor_default_43 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_43, 0.2719169557094574, 69, 0, 127, torch.uint8);  quantize_per_tensor_default_43 = None\n",
      "    layer4_0_aa = getattr(self.layer4, \"0\").aa(dequantize_per_tensor_default_43);  dequantize_per_tensor_default_43 = None\n",
      "    quantize_per_tensor_default_44 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_aa, 0.2719169557094574, 69, 0, 127, torch.uint8);  layer4_0_aa = None\n",
      "    dequantize_per_tensor_default_44 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_44, 0.2719169557094574, 69, 0, 127, torch.uint8);  quantize_per_tensor_default_44 = None\n",
      "    layer4_0_conv2 = getattr(self.layer4, \"0\").conv2(dequantize_per_tensor_default_44);  dequantize_per_tensor_default_44 = None\n",
      "    quantize_per_tensor_default_45 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_conv2, 0.2542303204536438, 75, 0, 127, torch.uint8);  layer4_0_conv2 = None\n",
      "    dequantize_per_tensor_default_45 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_45, 0.2542303204536438, 75, 0, 127, torch.uint8);  quantize_per_tensor_default_45 = None\n",
      "    layer4_0_downsample_0 = getattr(getattr(self.layer4, \"0\").downsample, \"0\")(dequantize_per_tensor_default_40);  dequantize_per_tensor_default_40 = None\n",
      "    quantize_per_tensor_default_46 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_downsample_0, 0.17691001296043396, 68, 0, 127, torch.uint8);  layer4_0_downsample_0 = None\n",
      "    dequantize_per_tensor_default_46 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_46, 0.17691001296043396, 68, 0, 127, torch.uint8);  quantize_per_tensor_default_46 = None\n",
      "    add_6 = dequantize_per_tensor_default_45 + dequantize_per_tensor_default_46;  dequantize_per_tensor_default_45 = dequantize_per_tensor_default_46 = None\n",
      "    layer4_0_act2 = getattr(self.layer4, \"0\").act2(add_6);  add_6 = None\n",
      "    quantize_per_tensor_default_47 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_0_act2, 0.1456831991672516, 0, 0, 127, torch.uint8);  layer4_0_act2 = None\n",
      "    dequantize_per_tensor_default_47 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_47, 0.1456831991672516, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_47 = None\n",
      "    layer4_1_conv1 = getattr(self.layer4, \"1\").conv1(dequantize_per_tensor_default_47)\n",
      "    quantize_per_tensor_default_48 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_conv1, 0.25498130917549133, 90, 0, 127, torch.uint8);  layer4_1_conv1 = None\n",
      "    dequantize_per_tensor_default_48 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_48, 0.25498130917549133, 90, 0, 127, torch.uint8);  quantize_per_tensor_default_48 = None\n",
      "    layer4_1_drop_block = getattr(self.layer4, \"1\").drop_block(dequantize_per_tensor_default_48);  dequantize_per_tensor_default_48 = None\n",
      "    quantize_per_tensor_default_49 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_drop_block, 0.25498130917549133, 90, 0, 127, torch.uint8);  layer4_1_drop_block = None\n",
      "    dequantize_per_tensor_default_49 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_49, 0.25498130917549133, 90, 0, 127, torch.uint8);  quantize_per_tensor_default_49 = None\n",
      "    layer4_1_act1 = getattr(self.layer4, \"1\").act1(dequantize_per_tensor_default_49);  dequantize_per_tensor_default_49 = None\n",
      "    quantize_per_tensor_default_50 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_act1, 0.25498130917549133, 90, 0, 127, torch.uint8);  layer4_1_act1 = None\n",
      "    dequantize_per_tensor_default_50 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_50, 0.25498130917549133, 90, 0, 127, torch.uint8);  quantize_per_tensor_default_50 = None\n",
      "    layer4_1_aa = getattr(self.layer4, \"1\").aa(dequantize_per_tensor_default_50);  dequantize_per_tensor_default_50 = None\n",
      "    quantize_per_tensor_default_51 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_aa, 0.25498130917549133, 90, 0, 127, torch.uint8);  layer4_1_aa = None\n",
      "    dequantize_per_tensor_default_51 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_51, 0.25498130917549133, 90, 0, 127, torch.uint8);  quantize_per_tensor_default_51 = None\n",
      "    layer4_1_conv2 = getattr(self.layer4, \"1\").conv2(dequantize_per_tensor_default_51);  dequantize_per_tensor_default_51 = None\n",
      "    quantize_per_tensor_default_52 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_conv2, 0.34592631459236145, 89, 0, 127, torch.uint8);  layer4_1_conv2 = None\n",
      "    dequantize_per_tensor_default_52 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_52, 0.34592631459236145, 89, 0, 127, torch.uint8);  quantize_per_tensor_default_52 = None\n",
      "    add_7 = dequantize_per_tensor_default_52 + dequantize_per_tensor_default_47;  dequantize_per_tensor_default_52 = dequantize_per_tensor_default_47 = None\n",
      "    layer4_1_act2 = getattr(self.layer4, \"1\").act2(add_7);  add_7 = None\n",
      "    quantize_per_tensor_default_53 = torch.ops.quantized_decomposed.quantize_per_tensor.default(layer4_1_act2, 0.15677042305469513, 0, 0, 127, torch.uint8);  layer4_1_act2 = None\n",
      "    dequantize_per_tensor_default_53 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_53, 0.15677042305469513, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_53 = None\n",
      "    global_pool_pool = self.global_pool.pool(dequantize_per_tensor_default_53);  dequantize_per_tensor_default_53 = None\n",
      "    quantize_per_tensor_default_54 = torch.ops.quantized_decomposed.quantize_per_tensor.default(global_pool_pool, 0.15677042305469513, 0, 0, 127, torch.uint8);  global_pool_pool = None\n",
      "    dequantize_per_tensor_default_54 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_54, 0.15677042305469513, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_54 = None\n",
      "    global_pool_flatten = self.global_pool.flatten(dequantize_per_tensor_default_54);  dequantize_per_tensor_default_54 = None\n",
      "    quantize_per_tensor_default_55 = torch.ops.quantized_decomposed.quantize_per_tensor.default(global_pool_flatten, 0.02608378976583481, 0, 0, 127, torch.uint8);  global_pool_flatten = None\n",
      "    dequantize_per_tensor_default_55 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_55, 0.02608378976583481, 0, 0, 127, torch.uint8);  quantize_per_tensor_default_55 = None\n",
      "    fc = self.fc(dequantize_per_tensor_default_55);  dequantize_per_tensor_default_55 = None\n",
      "    quantize_per_tensor_default_56 = torch.ops.quantized_decomposed.quantize_per_tensor.default(fc, 0.2907339632511139, 82, 0, 127, torch.uint8);  fc = None\n",
      "    dequantize_per_tensor_default_56 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_56, 0.2907339632511139, 82, 0, 127, torch.uint8);  quantize_per_tensor_default_56 = None\n",
      "    return dequantize_per_tensor_default_56\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ONNX export failed on an operator with unrecognized namespace quantized_decomposed::quantize_per_tensor. If you are trying to export a custom operator, make sure you registered it with the right domain and version.\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Diagnostic Run torch.onnx.export version 2.1.0.dev20230709+cu118 =======\n",
      "verbose: False, log level: 40\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 1 ERROR ========================\n",
      "ERROR: missing-custom-symbolic-function\n",
      "=======================================\n",
      "ONNX export failed on an operator with unrecognized namespace quantized_decomposed::quantize_per_tensor. If you are trying to export a custom operator, make sure you registered it with the right domain and version.\n",
      "None\n",
      "<Set verbose=True to see more details>\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnsupportedOperatorError",
     "evalue": "ONNX export failed on an operator with unrecognized namespace quantized_decomposed::quantize_per_tensor. If you are trying to export a custom operator, make sure you registered it with the right domain and version.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m/home/wrq/quant_learning/pytorch_quant_fx.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(quantized_model)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# print(prepared_model)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mexport(quantized_model, \u001b[39minput\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mresnet.onnx\u001b[39;49m\u001b[39m\"\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, input_names\u001b[39m=\u001b[39;49minput_names, output_names\u001b[39m=\u001b[39;49moutput_names, opset_version\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,do_constant_folding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# torch.jit.save(torch.jit.script(quantized_model), 'outQuant.pth')  # 保存量化后的模型\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# state_dict = torch.load('/home/xlx/code/quantize/outQuant.pth')  # 加载一个正常训练好的模型\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# model.load_state_dict(state_dict)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# model.to('cpu')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.22.13.50/home/wrq/quant_learning/pytorch_quant_fx.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# model.eval()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torch/onnx/utils.py:511\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39m@_beartype\u001b[39m\u001b[39m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[39m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m     _export(\n\u001b[1;32m    512\u001b[0m         model,\n\u001b[1;32m    513\u001b[0m         args,\n\u001b[1;32m    514\u001b[0m         f,\n\u001b[1;32m    515\u001b[0m         export_params,\n\u001b[1;32m    516\u001b[0m         verbose,\n\u001b[1;32m    517\u001b[0m         training,\n\u001b[1;32m    518\u001b[0m         input_names,\n\u001b[1;32m    519\u001b[0m         output_names,\n\u001b[1;32m    520\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type,\n\u001b[1;32m    521\u001b[0m         opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[1;32m    522\u001b[0m         do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[1;32m    523\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m    524\u001b[0m         keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[1;32m    525\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets,\n\u001b[1;32m    526\u001b[0m         export_modules_as_functions\u001b[39m=\u001b[39;49mexport_modules_as_functions,\n\u001b[1;32m    527\u001b[0m         autograd_inlining\u001b[39m=\u001b[39;49mautograd_inlining,\n\u001b[1;32m    528\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torch/onnx/utils.py:1593\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1590\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1593\u001b[0m graph, params_dict, torch_out \u001b[39m=\u001b[39m _model_to_graph(\n\u001b[1;32m   1594\u001b[0m     model,\n\u001b[1;32m   1595\u001b[0m     args,\n\u001b[1;32m   1596\u001b[0m     verbose,\n\u001b[1;32m   1597\u001b[0m     input_names,\n\u001b[1;32m   1598\u001b[0m     output_names,\n\u001b[1;32m   1599\u001b[0m     operator_export_type,\n\u001b[1;32m   1600\u001b[0m     val_do_constant_folding,\n\u001b[1;32m   1601\u001b[0m     fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1602\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   1603\u001b[0m     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1604\u001b[0m )\n\u001b[1;32m   1607\u001b[0m \u001b[39m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1608\u001b[0m defer_weight_export \u001b[39m=\u001b[39m (\n\u001b[1;32m   1609\u001b[0m     export_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _exporter_states\u001b[39m.\u001b[39mExportTypes\u001b[39m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1610\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torch/onnx/utils.py:1147\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1144\u001b[0m params_dict \u001b[39m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1146\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1147\u001b[0m     graph \u001b[39m=\u001b[39m _optimize_graph(\n\u001b[1;32m   1148\u001b[0m         graph,\n\u001b[1;32m   1149\u001b[0m         operator_export_type,\n\u001b[1;32m   1150\u001b[0m         _disable_torch_constant_prop\u001b[39m=\u001b[39;49m_disable_torch_constant_prop,\n\u001b[1;32m   1151\u001b[0m         fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1152\u001b[0m         params_dict\u001b[39m=\u001b[39;49mparams_dict,\n\u001b[1;32m   1153\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1154\u001b[0m         input_names\u001b[39m=\u001b[39;49minput_names,\n\u001b[1;32m   1155\u001b[0m         module\u001b[39m=\u001b[39;49mmodule,\n\u001b[1;32m   1156\u001b[0m     )\n\u001b[1;32m   1157\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1158\u001b[0m     torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mTorch IR graph at exception: \u001b[39m\u001b[39m\"\u001b[39m, graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torch/onnx/utils.py:673\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    670\u001b[0m     _C\u001b[39m.\u001b[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001b[1;32m    671\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m--> 673\u001b[0m graph \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39;49m_jit_pass_onnx(graph, operator_export_type)\n\u001b[1;32m    674\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    675\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_lint(graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/quant/lib/python3.9/site-packages/torch/onnx/utils.py:1946\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(graph, block, node, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[39mif\u001b[39;00m namespace \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39monnx\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1943\u001b[0m         \u001b[39m# Clone node to trigger ONNX shape inference\u001b[39;00m\n\u001b[1;32m   1944\u001b[0m         \u001b[39mreturn\u001b[39;00m graph_context\u001b[39m.\u001b[39mop(op_name, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mattrs, outputs\u001b[39m=\u001b[39mnode\u001b[39m.\u001b[39moutputsSize())  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m-> 1946\u001b[0m     \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mUnsupportedOperatorError(\n\u001b[1;32m   1947\u001b[0m         symbolic_function_name,\n\u001b[1;32m   1948\u001b[0m         opset_version,\n\u001b[1;32m   1949\u001b[0m         symbolic_function_group\u001b[39m.\u001b[39mget_min_supported()\n\u001b[1;32m   1950\u001b[0m         \u001b[39mif\u001b[39;00m symbolic_function_group\n\u001b[1;32m   1951\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1952\u001b[0m     )\n\u001b[1;32m   1954\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m:\n\u001b[1;32m   1955\u001b[0m     \u001b[39mif\u001b[39;00m operator_export_type \u001b[39m==\u001b[39m _C_onnx\u001b[39m.\u001b[39mOperatorExportTypes\u001b[39m.\u001b[39mONNX_FALLTHROUGH:\n",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m: ONNX export failed on an operator with unrecognized namespace quantized_decomposed::quantize_per_tensor. If you are trying to export a custom operator, make sure you registered it with the right domain and version."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "input = torch.randn(1, 3, 224,224)\n",
    "input_names = [ \"input\"]\n",
    "output_names = [ \"output\" ]\n",
    "print(quantized_model)\n",
    "# print(prepared_model)\n",
    "torch.onnx.export(quantized_model, input, \"resnet.onnx\", verbose=True, input_names=input_names, output_names=output_names, opset_version=16,do_constant_folding=True)\n",
    "# torch.jit.save(torch.jit.script(quantized_model), 'outQuant.pth')  # 保存量化后的模型\n",
    "# state_dict = torch.load('/home/xlx/code/quantize/outQuant.pth')  # 加载一个正常训练好的模型\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.to('cpu')\n",
    "# model.eval()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
